# ç¬¬11ç« ï¼šéƒ¨ç½²ä¸æ€§èƒ½ä¼˜åŒ–

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š
- æŒæ¡Chat-Roomé¡¹ç›®çš„éƒ¨ç½²ç­–ç•¥
- å­¦ä¼šæ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–æŠ€æœ¯
- å®ç°ç³»ç»Ÿçš„å¯æ‰©å±•æ€§è®¾è®¡
- æŒæ¡å®¹å™¨åŒ–éƒ¨ç½²æ–¹æ³•
- äº†è§£äº‘å¹³å°éƒ¨ç½²é€‰é¡¹
- ç¡®ä¿ç”Ÿäº§ç¯å¢ƒçš„ç¨³å®šè¿è¡Œ

## ğŸ“š ç« èŠ‚å†…å®¹

### 1. éƒ¨ç½²åŸºç¡€
- [ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æŒ‡å—](production-deployment.md)
- [å®¹å™¨åŒ–ä¸Dockeréƒ¨ç½²](docker-deployment.md)

### 2. æ€§èƒ½ä¼˜åŒ–
- [ç³»ç»Ÿæ€§èƒ½ç›‘æ§](performance-monitoring.md)
- [æ€§èƒ½ä¼˜åŒ–ç­–ç•¥](optimization-strategies.md)

### 3. è¿ç»´ç®¡ç†
- [æ—¥å¿—ç®¡ç†ä¸ç›‘æ§](logging-monitoring.md)
- [æ•…éšœæ’é™¤ä¸æ¢å¤](troubleshooting.md)

## ğŸš€ éƒ¨ç½²æ¶æ„è®¾è®¡

```mermaid
graph TD
    A[Chat-Rooméƒ¨ç½²æ¶æ„] --> B[è´Ÿè½½å‡è¡¡å±‚]
    A --> C[åº”ç”¨æœåŠ¡å±‚]
    A --> D[æ•°æ®å­˜å‚¨å±‚]
    A --> E[ç›‘æ§è¿ç»´å±‚]
    
    B --> B1[Nginxè´Ÿè½½å‡è¡¡]
    B --> B2[SSL/TLSç»ˆç«¯]
    B --> B3[é™æ€èµ„æºæœåŠ¡]
    
    C --> C1[Chat-RoomæœåŠ¡å™¨é›†ç¾¤]
    C --> C2[AIæœåŠ¡é›†ç¾¤]
    C --> C3[æ–‡ä»¶æœåŠ¡é›†ç¾¤]
    C --> C4[WebSocketç½‘å…³]
    
    D --> D1[ä¸»æ•°æ®åº“]
    D --> D2[è¯»å‰¯æœ¬æ•°æ®åº“]
    D --> D3[Redisç¼“å­˜]
    D --> D4[æ–‡ä»¶å­˜å‚¨]
    
    E --> E1[Prometheusç›‘æ§]
    E --> E2[Grafanaä»ªè¡¨æ¿]
    E --> E3[ELKæ—¥å¿—æ ˆ]
    E --> E4[å‘Šè­¦ç³»ç»Ÿ]
    
    style A fill:#e8f5e8
    style B fill:#fff3cd
    style C fill:#f8d7da
    style D fill:#e1f5fe
    style E fill:#f3e5f5
```

## ğŸ³ å®¹å™¨åŒ–éƒ¨ç½²

### Dockeré…ç½®

```dockerfile
# Chat-RoomæœåŠ¡å™¨Dockerfile
FROM python:3.11-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶ä¾èµ–æ–‡ä»¶
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# åˆ›å»ºérootç”¨æˆ·
RUN useradd -m -u 1000 chatroom && \
    chown -R chatroom:chatroom /app
USER chatroom

# æš´éœ²ç«¯å£
EXPOSE 8888

# å¥åº·æ£€æŸ¥
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import socket; s=socket.socket(); s.connect(('localhost', 8888)); s.close()" || exit 1

# å¯åŠ¨å‘½ä»¤
CMD ["python", "-m", "server.main"]
```

```yaml
# docker-compose.yml - å®Œæ•´éƒ¨ç½²é…ç½®
version: '3.8'

services:
  # Chat-RoomæœåŠ¡å™¨
  chatroom-server:
    build: .
    ports:
      - "8888:8888"
    environment:
      - DATABASE_URL=postgresql://chatroom:password@postgres:5432/chatroom
      - REDIS_URL=redis://redis:6379/0
      - AI_API_KEY=${AI_API_KEY}
      - LOG_LEVEL=INFO
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
    depends_on:
      - postgres
      - redis
    restart: unless-stopped
    networks:
      - chatroom-network
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'

  # æ•°æ®åº“
  postgres:
    image: postgres:15-alpine
    environment:
      - POSTGRES_DB=chatroom
      - POSTGRES_USER=chatroom
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    ports:
      - "5432:5432"
    restart: unless-stopped
    networks:
      - chatroom-network
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.3'

  # Redisç¼“å­˜
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    ports:
      - "6379:6379"
    restart: unless-stopped
    networks:
      - chatroom-network
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.1'

  # Nginxè´Ÿè½½å‡è¡¡
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - chatroom-server
    restart: unless-stopped
    networks:
      - chatroom-network

  # ç›‘æ§ç³»ç»Ÿ
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
    restart: unless-stopped
    networks:
      - chatroom-network

  # Grafanaä»ªè¡¨æ¿
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources
    restart: unless-stopped
    networks:
      - chatroom-network

volumes:
  postgres_data:
  redis_data:
  prometheus_data:
  grafana_data:

networks:
  chatroom-network:
    driver: bridge
```

## ğŸ“Š æ€§èƒ½ç›‘æ§å®ç°

### ç³»ç»Ÿç›‘æ§

```python
"""
Chat-Roomæ€§èƒ½ç›‘æ§ç³»ç»Ÿ
å®ç°å…¨é¢çš„ç³»ç»Ÿç›‘æ§å’Œæ€§èƒ½æŒ‡æ ‡æ”¶é›†
"""

import psutil
import time
import threading
import asyncio
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import json
import sqlite3
from shared.logger import get_logger

logger = get_logger("monitoring")

@dataclass
class SystemMetrics:
    """ç³»ç»ŸæŒ‡æ ‡"""
    timestamp: float
    cpu_percent: float
    memory_percent: float
    memory_used_mb: float
    memory_available_mb: float
    disk_usage_percent: float
    disk_free_gb: float
    network_bytes_sent: int
    network_bytes_recv: int
    active_connections: int
    load_average: List[float]

@dataclass
class ApplicationMetrics:
    """åº”ç”¨æŒ‡æ ‡"""
    timestamp: float
    active_users: int
    total_messages: int
    messages_per_minute: int
    ai_requests_per_minute: int
    file_transfers_active: int
    database_connections: int
    response_time_avg: float
    error_rate: float

class MetricsCollector:
    """æŒ‡æ ‡æ”¶é›†å™¨"""
    
    def __init__(self, collection_interval: float = 60.0):
        self.collection_interval = collection_interval
        self.running = False
        self.metrics_history: List[SystemMetrics] = []
        self.app_metrics_history: List[ApplicationMetrics] = []
        self.max_history_size = 1440  # 24å°æ—¶çš„åˆ†é’Ÿæ•°
        
        # ç½‘ç»œç»Ÿè®¡åŸºçº¿
        self.network_baseline = psutil.net_io_counters()
        
        # åº”ç”¨æŒ‡æ ‡å›è°ƒ
        self.app_metrics_callback: Optional[callable] = None
    
    def start_collection(self):
        """å¼€å§‹æ”¶é›†æŒ‡æ ‡"""
        self.running = True
        
        collection_thread = threading.Thread(
            target=self._collection_loop,
            daemon=True
        )
        collection_thread.start()
        
        logger.info("æŒ‡æ ‡æ”¶é›†å™¨å·²å¯åŠ¨")
    
    def stop_collection(self):
        """åœæ­¢æ”¶é›†æŒ‡æ ‡"""
        self.running = False
        logger.info("æŒ‡æ ‡æ”¶é›†å™¨å·²åœæ­¢")
    
    def _collection_loop(self):
        """æŒ‡æ ‡æ”¶é›†å¾ªç¯"""
        while self.running:
            try:
                # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
                system_metrics = self._collect_system_metrics()
                self.metrics_history.append(system_metrics)
                
                # æ”¶é›†åº”ç”¨æŒ‡æ ‡
                if self.app_metrics_callback:
                    app_metrics = self.app_metrics_callback()
                    if app_metrics:
                        self.app_metrics_history.append(app_metrics)
                
                # é™åˆ¶å†å²è®°å½•å¤§å°
                if len(self.metrics_history) > self.max_history_size:
                    self.metrics_history.pop(0)
                
                if len(self.app_metrics_history) > self.max_history_size:
                    self.app_metrics_history.pop(0)
                
                # è®°å½•å…³é”®æŒ‡æ ‡
                self._log_metrics(system_metrics)
                
                time.sleep(self.collection_interval)
                
            except Exception as e:
                logger.error(f"æŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")
                time.sleep(self.collection_interval)
    
    def _collect_system_metrics(self) -> SystemMetrics:
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        
        # CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        
        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory = psutil.virtual_memory()
        
        # ç£ç›˜ä½¿ç”¨æƒ…å†µ
        disk = psutil.disk_usage('/')
        
        # ç½‘ç»œç»Ÿè®¡
        network = psutil.net_io_counters()
        
        # ç½‘ç»œè¿æ¥æ•°
        connections = len(psutil.net_connections())
        
        # ç³»ç»Ÿè´Ÿè½½
        try:
            load_avg = list(psutil.getloadavg())
        except AttributeError:
            # Windowsç³»ç»Ÿä¸æ”¯æŒgetloadavg
            load_avg = [0.0, 0.0, 0.0]
        
        return SystemMetrics(
            timestamp=time.time(),
            cpu_percent=cpu_percent,
            memory_percent=memory.percent,
            memory_used_mb=memory.used / 1024 / 1024,
            memory_available_mb=memory.available / 1024 / 1024,
            disk_usage_percent=disk.percent,
            disk_free_gb=disk.free / 1024 / 1024 / 1024,
            network_bytes_sent=network.bytes_sent,
            network_bytes_recv=network.bytes_recv,
            active_connections=connections,
            load_average=load_avg
        )
    
    def _log_metrics(self, metrics: SystemMetrics):
        """è®°å½•å…³é”®æŒ‡æ ‡"""
        
        # è®°å½•é«˜CPUä½¿ç”¨ç‡
        if metrics.cpu_percent > 80:
            logger.warning(f"é«˜CPUä½¿ç”¨ç‡: {metrics.cpu_percent:.1f}%")
        
        # è®°å½•é«˜å†…å­˜ä½¿ç”¨ç‡
        if metrics.memory_percent > 85:
            logger.warning(f"é«˜å†…å­˜ä½¿ç”¨ç‡: {metrics.memory_percent:.1f}%")
        
        # è®°å½•ç£ç›˜ç©ºé—´ä¸è¶³
        if metrics.disk_usage_percent > 90:
            logger.warning(f"ç£ç›˜ç©ºé—´ä¸è¶³: {metrics.disk_usage_percent:.1f}%")
        
        # è®°å½•é«˜è¿æ¥æ•°
        if metrics.active_connections > 1000:
            logger.warning(f"é«˜è¿æ¥æ•°: {metrics.active_connections}")
    
    def get_current_metrics(self) -> Optional[SystemMetrics]:
        """è·å–å½“å‰æŒ‡æ ‡"""
        return self.metrics_history[-1] if self.metrics_history else None
    
    def get_metrics_summary(self, hours: int = 1) -> Dict[str, Any]:
        """è·å–æŒ‡æ ‡æ‘˜è¦"""
        
        if not self.metrics_history:
            return {}
        
        # è®¡ç®—æ—¶é—´èŒƒå›´
        cutoff_time = time.time() - (hours * 3600)
        recent_metrics = [m for m in self.metrics_history if m.timestamp >= cutoff_time]
        
        if not recent_metrics:
            return {}
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        cpu_values = [m.cpu_percent for m in recent_metrics]
        memory_values = [m.memory_percent for m in recent_metrics]
        
        return {
            "time_range_hours": hours,
            "sample_count": len(recent_metrics),
            "cpu": {
                "avg": sum(cpu_values) / len(cpu_values),
                "max": max(cpu_values),
                "min": min(cpu_values)
            },
            "memory": {
                "avg": sum(memory_values) / len(memory_values),
                "max": max(memory_values),
                "min": min(memory_values)
            },
            "current": asdict(recent_metrics[-1])
        }

class PerformanceOptimizer:
    """æ€§èƒ½ä¼˜åŒ–å™¨"""
    
    def __init__(self, metrics_collector: MetricsCollector):
        self.metrics_collector = metrics_collector
        self.optimization_rules = []
        self.running = False
        
        # æ³¨å†Œä¼˜åŒ–è§„åˆ™
        self._register_optimization_rules()
    
    def _register_optimization_rules(self):
        """æ³¨å†Œä¼˜åŒ–è§„åˆ™"""
        
        self.optimization_rules = [
            {
                "name": "é«˜CPUä½¿ç”¨ç‡ä¼˜åŒ–",
                "condition": lambda m: m.cpu_percent > 80,
                "action": self._optimize_cpu_usage,
                "cooldown": 300  # 5åˆ†é’Ÿå†·å´æ—¶é—´
            },
            {
                "name": "é«˜å†…å­˜ä½¿ç”¨ç‡ä¼˜åŒ–",
                "condition": lambda m: m.memory_percent > 85,
                "action": self._optimize_memory_usage,
                "cooldown": 300
            },
            {
                "name": "è¿æ¥æ•°ä¼˜åŒ–",
                "condition": lambda m: m.active_connections > 500,
                "action": self._optimize_connections,
                "cooldown": 600  # 10åˆ†é’Ÿå†·å´æ—¶é—´
            }
        ]
    
    def start_optimization(self):
        """å¼€å§‹æ€§èƒ½ä¼˜åŒ–"""
        self.running = True
        
        optimization_thread = threading.Thread(
            target=self._optimization_loop,
            daemon=True
        )
        optimization_thread.start()
        
        logger.info("æ€§èƒ½ä¼˜åŒ–å™¨å·²å¯åŠ¨")
    
    def stop_optimization(self):
        """åœæ­¢æ€§èƒ½ä¼˜åŒ–"""
        self.running = False
        logger.info("æ€§èƒ½ä¼˜åŒ–å™¨å·²åœæ­¢")
    
    def _optimization_loop(self):
        """ä¼˜åŒ–å¾ªç¯"""
        rule_last_triggered = {}
        
        while self.running:
            try:
                current_metrics = self.metrics_collector.get_current_metrics()
                if not current_metrics:
                    time.sleep(60)
                    continue
                
                current_time = time.time()
                
                # æ£€æŸ¥ä¼˜åŒ–è§„åˆ™
                for rule in self.optimization_rules:
                    rule_name = rule["name"]
                    
                    # æ£€æŸ¥å†·å´æ—¶é—´
                    last_triggered = rule_last_triggered.get(rule_name, 0)
                    if current_time - last_triggered < rule["cooldown"]:
                        continue
                    
                    # æ£€æŸ¥è§¦å‘æ¡ä»¶
                    if rule["condition"](current_metrics):
                        logger.info(f"è§¦å‘ä¼˜åŒ–è§„åˆ™: {rule_name}")
                        
                        try:
                            rule["action"](current_metrics)
                            rule_last_triggered[rule_name] = current_time
                        except Exception as e:
                            logger.error(f"æ‰§è¡Œä¼˜åŒ–è§„åˆ™å¤±è´¥ {rule_name}: {e}")
                
                time.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"ä¼˜åŒ–å¾ªç¯å¤±è´¥: {e}")
                time.sleep(60)
    
    def _optimize_cpu_usage(self, metrics: SystemMetrics):
        """ä¼˜åŒ–CPUä½¿ç”¨ç‡"""
        logger.info("æ‰§è¡ŒCPUä¼˜åŒ–ç­–ç•¥")
        
        # å®æ–½CPUä¼˜åŒ–ç­–ç•¥
        # 1. é™ä½éå…³é”®ä»»åŠ¡çš„ä¼˜å…ˆçº§
        # 2. å¯ç”¨CPUç¼“å­˜
        # 3. ä¼˜åŒ–ç®—æ³•å¤æ‚åº¦
        
        # ç¤ºä¾‹ï¼šè§¦å‘åƒåœ¾å›æ”¶
        import gc
        gc.collect()
        
        logger.info("CPUä¼˜åŒ–ç­–ç•¥æ‰§è¡Œå®Œæˆ")
    
    def _optimize_memory_usage(self, metrics: SystemMetrics):
        """ä¼˜åŒ–å†…å­˜ä½¿ç”¨ç‡"""
        logger.info("æ‰§è¡Œå†…å­˜ä¼˜åŒ–ç­–ç•¥")
        
        # å®æ–½å†…å­˜ä¼˜åŒ–ç­–ç•¥
        # 1. æ¸…ç†ç¼“å­˜
        # 2. é‡Šæ”¾ä¸å¿…è¦çš„å¯¹è±¡
        # 3. ä¼˜åŒ–æ•°æ®ç»“æ„
        
        # ç¤ºä¾‹ï¼šå¼ºåˆ¶åƒåœ¾å›æ”¶
        import gc
        collected = gc.collect()
        logger.info(f"åƒåœ¾å›æ”¶é‡Šæ”¾äº† {collected} ä¸ªå¯¹è±¡")
        
        logger.info("å†…å­˜ä¼˜åŒ–ç­–ç•¥æ‰§è¡Œå®Œæˆ")
    
    def _optimize_connections(self, metrics: SystemMetrics):
        """ä¼˜åŒ–è¿æ¥æ•°"""
        logger.info("æ‰§è¡Œè¿æ¥ä¼˜åŒ–ç­–ç•¥")
        
        # å®æ–½è¿æ¥ä¼˜åŒ–ç­–ç•¥
        # 1. æ¸…ç†ç©ºé—²è¿æ¥
        # 2. å¯ç”¨è¿æ¥æ± 
        # 3. å®æ–½è¿æ¥é™åˆ¶
        
        logger.info("è¿æ¥ä¼˜åŒ–ç­–ç•¥æ‰§è¡Œå®Œæˆ")

class AlertManager:
    """å‘Šè­¦ç®¡ç†å™¨"""
    
    def __init__(self, metrics_collector: MetricsCollector):
        self.metrics_collector = metrics_collector
        self.alert_rules = []
        self.alert_history = []
        self.running = False
        
        # æ³¨å†Œå‘Šè­¦è§„åˆ™
        self._register_alert_rules()
    
    def _register_alert_rules(self):
        """æ³¨å†Œå‘Šè­¦è§„åˆ™"""
        
        self.alert_rules = [
            {
                "name": "CPUä½¿ç”¨ç‡è¿‡é«˜",
                "condition": lambda m: m.cpu_percent > 90,
                "severity": "critical",
                "message": "CPUä½¿ç”¨ç‡è¶…è¿‡90%"
            },
            {
                "name": "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜",
                "condition": lambda m: m.memory_percent > 95,
                "severity": "critical",
                "message": "å†…å­˜ä½¿ç”¨ç‡è¶…è¿‡95%"
            },
            {
                "name": "ç£ç›˜ç©ºé—´ä¸è¶³",
                "condition": lambda m: m.disk_usage_percent > 95,
                "severity": "warning",
                "message": "ç£ç›˜ä½¿ç”¨ç‡è¶…è¿‡95%"
            }
        ]
    
    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§å‘Šè­¦"""
        self.running = True
        
        monitoring_thread = threading.Thread(
            target=self._monitoring_loop,
            daemon=True
        )
        monitoring_thread.start()
        
        logger.info("å‘Šè­¦ç›‘æ§å·²å¯åŠ¨")
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§å‘Šè­¦"""
        self.running = False
        logger.info("å‘Šè­¦ç›‘æ§å·²åœæ­¢")
    
    def _monitoring_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.running:
            try:
                current_metrics = self.metrics_collector.get_current_metrics()
                if not current_metrics:
                    time.sleep(30)
                    continue
                
                # æ£€æŸ¥å‘Šè­¦è§„åˆ™
                for rule in self.alert_rules:
                    if rule["condition"](current_metrics):
                        self._trigger_alert(rule, current_metrics)
                
                time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                logger.error(f"å‘Šè­¦ç›‘æ§å¤±è´¥: {e}")
                time.sleep(30)
    
    def _trigger_alert(self, rule: Dict[str, Any], metrics: SystemMetrics):
        """è§¦å‘å‘Šè­¦"""
        
        alert = {
            "timestamp": time.time(),
            "rule_name": rule["name"],
            "severity": rule["severity"],
            "message": rule["message"],
            "metrics": asdict(metrics)
        }
        
        self.alert_history.append(alert)
        
        # è®°å½•å‘Šè­¦æ—¥å¿—
        log_level = logger.critical if rule["severity"] == "critical" else logger.warning
        log_level(f"å‘Šè­¦è§¦å‘: {rule['name']} - {rule['message']}")
        
        # å‘é€å‘Šè­¦é€šçŸ¥ï¼ˆé‚®ä»¶ã€çŸ­ä¿¡ã€Webhookç­‰ï¼‰
        self._send_alert_notification(alert)
    
    def _send_alert_notification(self, alert: Dict[str, Any]):
        """å‘é€å‘Šè­¦é€šçŸ¥"""
        # TODO: å®ç°å‘Šè­¦é€šçŸ¥æœºåˆ¶
        # å¯ä»¥é›†æˆé‚®ä»¶ã€çŸ­ä¿¡ã€Slackã€é’‰é’‰ç­‰é€šçŸ¥æ–¹å¼
        pass

# ä½¿ç”¨ç¤ºä¾‹
def setup_monitoring_system():
    """è®¾ç½®ç›‘æ§ç³»ç»Ÿ"""
    
    # åˆ›å»ºæŒ‡æ ‡æ”¶é›†å™¨
    metrics_collector = MetricsCollector(collection_interval=60.0)
    
    # åˆ›å»ºæ€§èƒ½ä¼˜åŒ–å™¨
    optimizer = PerformanceOptimizer(metrics_collector)
    
    # åˆ›å»ºå‘Šè­¦ç®¡ç†å™¨
    alert_manager = AlertManager(metrics_collector)
    
    # å¯åŠ¨ç›‘æ§ç³»ç»Ÿ
    metrics_collector.start_collection()
    optimizer.start_optimization()
    alert_manager.start_monitoring()
    
    logger.info("ç›‘æ§ç³»ç»Ÿå·²å¯åŠ¨")
    
    return {
        "metrics_collector": metrics_collector,
        "optimizer": optimizer,
        "alert_manager": alert_manager
    }

if __name__ == "__main__":
    monitoring_system = setup_monitoring_system()
    
    try:
        # ä¿æŒç¨‹åºè¿è¡Œ
        while True:
            time.sleep(60)
            
            # æ˜¾ç¤ºå½“å‰æŒ‡æ ‡
            current_metrics = monitoring_system["metrics_collector"].get_current_metrics()
            if current_metrics:
                print(f"CPU: {current_metrics.cpu_percent:.1f}%, "
                      f"å†…å­˜: {current_metrics.memory_percent:.1f}%, "
                      f"è¿æ¥æ•°: {current_metrics.active_connections}")
    
    except KeyboardInterrupt:
        logger.info("åœæ­¢ç›‘æ§ç³»ç»Ÿ")
        monitoring_system["metrics_collector"].stop_collection()
        monitoring_system["optimizer"].stop_optimization()
        monitoring_system["alert_manager"].stop_monitoring()
```

## ğŸ“‹ å­¦ä¹ æ£€æŸ¥æ¸…å•

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œè¯·ç¡®è®¤æ‚¨èƒ½å¤Ÿï¼š

### éƒ¨ç½²åŸºç¡€
- [ ] ç†è§£ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²çš„è¦æ±‚å’ŒæŒ‘æˆ˜
- [ ] æŒæ¡Dockerå®¹å™¨åŒ–éƒ¨ç½²æ–¹æ³•
- [ ] é…ç½®è´Ÿè½½å‡è¡¡å’Œåå‘ä»£ç†
- [ ] å®ç°æ•°æ®åº“å’Œç¼“å­˜çš„éƒ¨ç½²

### æ€§èƒ½ç›‘æ§
- [ ] å®ç°ç³»ç»ŸæŒ‡æ ‡çš„æ”¶é›†å’Œç›‘æ§
- [ ] è®¾ç½®æ€§èƒ½å‘Šè­¦å’Œé€šçŸ¥æœºåˆ¶
- [ ] ä½¿ç”¨ç›‘æ§å·¥å…·åˆ†æç³»ç»ŸçŠ¶æ€
- [ ] å»ºç«‹æ€§èƒ½åŸºçº¿å’Œè¶‹åŠ¿åˆ†æ

### ä¼˜åŒ–ç­–ç•¥
- [ ] è¯†åˆ«æ€§èƒ½ç“¶é¢ˆå’Œä¼˜åŒ–ç‚¹
- [ ] å®ç°è‡ªåŠ¨åŒ–æ€§èƒ½ä¼˜åŒ–
- [ ] ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢å’Œè¿æ¥
- [ ] å®ç°ç¼“å­˜ç­–ç•¥å’ŒCDNåŠ é€Ÿ

### è¿ç»´ç®¡ç†
- [ ] å»ºç«‹æ—¥å¿—ç®¡ç†å’Œåˆ†æç³»ç»Ÿ
- [ ] å®ç°æ•…éšœæ£€æµ‹å’Œè‡ªåŠ¨æ¢å¤
- [ ] åˆ¶å®šå¤‡ä»½å’Œç¾éš¾æ¢å¤è®¡åˆ’
- [ ] å»ºç«‹è¿ç»´ç›‘æ§å’Œå‘Šè­¦ä½“ç³»

## ğŸ”— ç›¸å…³èµ„æº

- [Dockerå®˜æ–¹æ–‡æ¡£](https://docs.docker.com/)
- [Kuberneteséƒ¨ç½²æŒ‡å—](https://kubernetes.io/docs/)
- [Prometheusç›‘æ§ç³»ç»Ÿ](https://prometheus.io/docs/)
- [Nginxé…ç½®æŒ‡å—](https://nginx.org/en/docs/)

## ğŸ“š ä¸‹ä¸€æ­¥

éƒ¨ç½²ä¸æ€§èƒ½ä¼˜åŒ–å­¦ä¹ å®Œæˆåï¼Œè¯·ç»§ç»­å­¦ä¹ ï¼š
- [ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æŒ‡å—](production-deployment.md)

---

**æŒæ¡éƒ¨ç½²å’Œä¼˜åŒ–æŠ€èƒ½ï¼Œè®©Chat-Roomåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ç¨³å®šé«˜æ•ˆè¿è¡Œï¼** ğŸš€
