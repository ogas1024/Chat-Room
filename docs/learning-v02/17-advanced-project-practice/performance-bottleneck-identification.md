# æ€§èƒ½ç“¶é¢ˆè¯†åˆ«

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬èŠ‚å­¦ä¹ ï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š
- æŒæ¡ç³»ç»Ÿæ€§çš„æ€§èƒ½åˆ†ææ–¹æ³•
- å­¦ä¼šä½¿ç”¨å„ç§æ€§èƒ½ç›‘æ§å·¥å…·
- äº†è§£å¸¸è§çš„æ€§èƒ½ç“¶é¢ˆç±»å‹å’Œç‰¹å¾
- æŒæ¡æ€§èƒ½æ•°æ®çš„æ”¶é›†å’Œåˆ†ææŠ€å·§
- å­¦ä¼šåˆ¶å®šé’ˆå¯¹æ€§çš„ä¼˜åŒ–ç­–ç•¥

## ğŸ“– æ€§èƒ½ç“¶é¢ˆæ¦‚è¿°

æ€§èƒ½ç“¶é¢ˆæ˜¯é™åˆ¶ç³»ç»Ÿæ•´ä½“æ€§èƒ½çš„å…³é”®å› ç´ ã€‚åœ¨Chat-Roomé¡¹ç›®ä¸­ï¼Œå¸¸è§çš„æ€§èƒ½ç“¶é¢ˆåŒ…æ‹¬ç½‘ç»œå»¶è¿Ÿã€æ•°æ®åº“æŸ¥è¯¢ã€å†…å­˜ä½¿ç”¨ã€CPUè®¡ç®—ç­‰ã€‚è¯†åˆ«å’Œè§£å†³è¿™äº›ç“¶é¢ˆæ˜¯æå‡ç”¨æˆ·ä½“éªŒçš„å…³é”®ã€‚

### æ€§èƒ½åˆ†ææ¡†æ¶

```mermaid
graph TD
    A[æ€§èƒ½ç›‘æ§] --> B[æ•°æ®æ”¶é›†]
    B --> C[ç“¶é¢ˆè¯†åˆ«]
    C --> D[æ ¹å› åˆ†æ]
    D --> E[ä¼˜åŒ–æ–¹æ¡ˆ]
    E --> F[æ•ˆæœéªŒè¯]

    A1[ç³»ç»ŸæŒ‡æ ‡] --> A
    A2[åº”ç”¨æŒ‡æ ‡] --> A
    A3[ç”¨æˆ·ä½“éªŒ] --> A

    B1[å®æ—¶ç›‘æ§] --> B
    B2[å†å²æ•°æ®] --> B
    B3[å‹åŠ›æµ‹è¯•] --> B

    C1[CPUç“¶é¢ˆ] --> C
    C2[å†…å­˜ç“¶é¢ˆ] --> C
    C3[IOç“¶é¢ˆ] --> C
    C4[ç½‘ç»œç“¶é¢ˆ] --> C

    style A fill:#e8f5e8
    style C fill:#fff3cd
    style E fill:#f8d7da
```

## ğŸ” Chat-Roomæ€§èƒ½ç›‘æ§ç³»ç»Ÿ

### 1. æ€§èƒ½ç›‘æ§å™¨å®ç°

```python
"""
Chat-Roomæ€§èƒ½ç›‘æ§ç³»ç»Ÿ
"""

import time
import psutil
import threading
import sqlite3
from typing import Dict, List, Optional, Any, Callable
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import json
import statistics
from collections import deque, defaultdict


@dataclass
class PerformanceMetric:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®æ¨¡å‹"""
    timestamp: float
    metric_name: str
    value: float
    unit: str
    tags: Dict[str, str] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "timestamp": self.timestamp,
            "metric_name": self.metric_name,
            "value": self.value,
            "unit": self.unit,
            "tags": self.tags
        }


class SystemMonitor:
    """ç³»ç»Ÿæ€§èƒ½ç›‘æ§å™¨"""

    def __init__(self, collection_interval: float = 1.0):
        self.collection_interval = collection_interval
        self.metrics_buffer = deque(maxlen=1000)  # ä¿ç•™æœ€è¿‘1000ä¸ªæ•°æ®ç‚¹
        self.is_monitoring = False
        self.monitor_thread = None

        # æ€§èƒ½é˜ˆå€¼é…ç½®
        self.thresholds = {
            "cpu_usage": 80.0,      # CPUä½¿ç”¨ç‡é˜ˆå€¼
            "memory_usage": 85.0,   # å†…å­˜ä½¿ç”¨ç‡é˜ˆå€¼
            "disk_usage": 90.0,     # ç£ç›˜ä½¿ç”¨ç‡é˜ˆå€¼
            "response_time": 1000.0 # å“åº”æ—¶é—´é˜ˆå€¼(ms)
        }

        # å‘Šè­¦å›è°ƒ
        self.alert_callbacks: List[Callable] = []

    def start_monitoring(self):
        """å¼€å§‹ç›‘æ§"""
        if self.is_monitoring:
            return

        self.is_monitoring = True
        self.monitor_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self.monitor_thread.start()
        print("ç³»ç»Ÿæ€§èƒ½ç›‘æ§å·²å¯åŠ¨")

    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.is_monitoring = False
        if self.monitor_thread:
            self.monitor_thread.join()
        print("ç³»ç»Ÿæ€§èƒ½ç›‘æ§å·²åœæ­¢")

    def _monitoring_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.is_monitoring:
            try:
                # æ”¶é›†ç³»ç»ŸæŒ‡æ ‡
                self._collect_system_metrics()
                time.sleep(self.collection_interval)
            except Exception as e:
                print(f"ç›‘æ§è¿‡ç¨‹ä¸­å‡ºé”™: {e}")

    def _collect_system_metrics(self):
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        timestamp = time.time()

        # CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=None)
        self._add_metric("cpu_usage", cpu_percent, "percent", timestamp)

        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory = psutil.virtual_memory()
        self._add_metric("memory_usage", memory.percent, "percent", timestamp)
        self._add_metric("memory_available", memory.available / (1024**3), "GB", timestamp)

        # ç£ç›˜ä½¿ç”¨æƒ…å†µ
        disk = psutil.disk_usage('/')
        disk_percent = (disk.used / disk.total) * 100
        self._add_metric("disk_usage", disk_percent, "percent", timestamp)

        # ç½‘ç»œIO
        net_io = psutil.net_io_counters()
        self._add_metric("network_bytes_sent", net_io.bytes_sent, "bytes", timestamp)
        self._add_metric("network_bytes_recv", net_io.bytes_recv, "bytes", timestamp)

        # è¿›ç¨‹æ•°é‡
        process_count = len(psutil.pids())
        self._add_metric("process_count", process_count, "count", timestamp)

        # æ£€æŸ¥é˜ˆå€¼å‘Šè­¦
        self._check_thresholds(timestamp)

    def _add_metric(self, name: str, value: float, unit: str, timestamp: float):
        """æ·»åŠ æŒ‡æ ‡"""
        metric = PerformanceMetric(
            timestamp=timestamp,
            metric_name=name,
            value=value,
            unit=unit
        )
        self.metrics_buffer.append(metric)

    def _check_thresholds(self, timestamp: float):
        """æ£€æŸ¥é˜ˆå€¼å‘Šè­¦"""
        recent_metrics = self.get_recent_metrics(60)  # æœ€è¿‘1åˆ†é’Ÿçš„æ•°æ®

        for metric_name, threshold in self.thresholds.items():
            values = [m.value for m in recent_metrics if m.metric_name == metric_name]
            if values:
                avg_value = statistics.mean(values)
                if avg_value > threshold:
                    self._trigger_alert(metric_name, avg_value, threshold, timestamp)

    def _trigger_alert(self, metric_name: str, value: float, threshold: float, timestamp: float):
        """è§¦å‘å‘Šè­¦"""
        alert_data = {
            "metric_name": metric_name,
            "current_value": value,
            "threshold": threshold,
            "timestamp": timestamp,
            "severity": "warning" if value < threshold * 1.2 else "critical"
        }

        for callback in self.alert_callbacks:
            try:
                callback(alert_data)
            except Exception as e:
                print(f"å‘Šè­¦å›è°ƒæ‰§è¡Œå¤±è´¥: {e}")

    def get_recent_metrics(self, seconds: int = 300) -> List[PerformanceMetric]:
        """è·å–æœ€è¿‘çš„æŒ‡æ ‡æ•°æ®"""
        cutoff_time = time.time() - seconds
        return [m for m in self.metrics_buffer if m.timestamp >= cutoff_time]

    def get_metric_statistics(self, metric_name: str, seconds: int = 300) -> Dict[str, float]:
        """è·å–æŒ‡æ ‡ç»Ÿè®¡ä¿¡æ¯"""
        recent_metrics = self.get_recent_metrics(seconds)
        values = [m.value for m in recent_metrics if m.metric_name == metric_name]

        if not values:
            return {}

        return {
            "count": len(values),
            "min": min(values),
            "max": max(values),
            "mean": statistics.mean(values),
            "median": statistics.median(values),
            "std_dev": statistics.stdev(values) if len(values) > 1 else 0
        }

    def add_alert_callback(self, callback: Callable):
        """æ·»åŠ å‘Šè­¦å›è°ƒ"""
        self.alert_callbacks.append(callback)


class ApplicationMonitor:
    """åº”ç”¨æ€§èƒ½ç›‘æ§å™¨"""

    def __init__(self):
        self.request_times = deque(maxlen=1000)
        self.error_counts = defaultdict(int)
        self.active_connections = 0
        self.message_counts = defaultdict(int)
        self.start_time = time.time()

    def record_request_time(self, operation: str, duration: float):
        """è®°å½•è¯·æ±‚æ—¶é—´"""
        self.request_times.append({
            "operation": operation,
            "duration": duration,
            "timestamp": time.time()
        })

    def record_error(self, error_type: str):
        """è®°å½•é”™è¯¯"""
        self.error_counts[error_type] += 1

    def update_connection_count(self, count: int):
        """æ›´æ–°è¿æ¥æ•°"""
        self.active_connections = count

    def record_message(self, message_type: str):
        """è®°å½•æ¶ˆæ¯"""
        self.message_counts[message_type] += 1

    def get_performance_summary(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        uptime = time.time() - self.start_time

        # è®¡ç®—è¯·æ±‚æ—¶é—´ç»Ÿè®¡
        recent_requests = [r for r in self.request_times
                          if time.time() - r["timestamp"] < 300]  # æœ€è¿‘5åˆ†é’Ÿ

        request_stats = {}
        if recent_requests:
            durations = [r["duration"] for r in recent_requests]
            request_stats = {
                "total_requests": len(recent_requests),
                "avg_response_time": statistics.mean(durations),
                "p95_response_time": self._percentile(durations, 95),
                "p99_response_time": self._percentile(durations, 99)
            }

        return {
            "uptime_seconds": uptime,
            "active_connections": self.active_connections,
            "total_errors": sum(self.error_counts.values()),
            "error_breakdown": dict(self.error_counts),
            "message_counts": dict(self.message_counts),
            "request_statistics": request_stats
        }

    def _percentile(self, data: List[float], percentile: int) -> float:
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        if not data:
            return 0.0

        sorted_data = sorted(data)
        index = int((percentile / 100.0) * len(sorted_data))
        return sorted_data[min(index, len(sorted_data) - 1)]


class PerformanceProfiler:
    """æ€§èƒ½åˆ†æå™¨"""

    def __init__(self):
        self.function_times = defaultdict(list)
        self.call_counts = defaultdict(int)

    def profile_function(self, func_name: str):
        """å‡½æ•°æ€§èƒ½åˆ†æè£…é¥°å™¨"""
        def decorator(func):
            def wrapper(*args, **kwargs):
                start_time = time.time()
                try:
                    result = func(*args, **kwargs)
                    return result
                finally:
                    end_time = time.time()
                    duration = (end_time - start_time) * 1000  # è½¬æ¢ä¸ºæ¯«ç§’

                    self.function_times[func_name].append(duration)
                    self.call_counts[func_name] += 1

                    # ä¿ç•™æœ€è¿‘100æ¬¡è°ƒç”¨çš„æ•°æ®
                    if len(self.function_times[func_name]) > 100:
                        self.function_times[func_name] = self.function_times[func_name][-100:]

            return wrapper
        return decorator

    def get_function_stats(self, func_name: str) -> Dict[str, Any]:
        """è·å–å‡½æ•°æ€§èƒ½ç»Ÿè®¡"""
        times = self.function_times.get(func_name, [])
        if not times:
            return {}

        return {
            "call_count": self.call_counts[func_name],
            "avg_time_ms": statistics.mean(times),
            "min_time_ms": min(times),
            "max_time_ms": max(times),
            "p95_time_ms": self._percentile(times, 95),
            "total_time_ms": sum(times)
        }

    def get_all_stats(self) -> Dict[str, Dict[str, Any]]:
        """è·å–æ‰€æœ‰å‡½æ•°çš„æ€§èƒ½ç»Ÿè®¡"""
        return {func_name: self.get_function_stats(func_name)
                for func_name in self.function_times.keys()}

    def _percentile(self, data: List[float], percentile: int) -> float:
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        if not data:
            return 0.0

        sorted_data = sorted(data)
        index = int((percentile / 100.0) * len(sorted_data))
        return sorted_data[min(index, len(sorted_data) - 1)]


# ç“¶é¢ˆåˆ†æå™¨
class BottleneckAnalyzer:
    """ç“¶é¢ˆåˆ†æå™¨"""

    def __init__(self, system_monitor: SystemMonitor, app_monitor: ApplicationMonitor):
        self.system_monitor = system_monitor
        self.app_monitor = app_monitor

        # ç“¶é¢ˆæ£€æµ‹è§„åˆ™
        self.bottleneck_rules = {
            "cpu_bottleneck": {
                "condition": lambda stats: stats.get("cpu_usage", {}).get("mean", 0) > 80,
                "description": "CPUä½¿ç”¨ç‡è¿‡é«˜",
                "suggestions": [
                    "ä¼˜åŒ–è®¡ç®—å¯†é›†å‹æ“ä½œ",
                    "ä½¿ç”¨å¼‚æ­¥å¤„ç†",
                    "è€ƒè™‘æ°´å¹³æ‰©å±•"
                ]
            },
            "memory_bottleneck": {
                "condition": lambda stats: stats.get("memory_usage", {}).get("mean", 0) > 85,
                "description": "å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜",
                "suggestions": [
                    "æ£€æŸ¥å†…å­˜æ³„æ¼",
                    "ä¼˜åŒ–æ•°æ®ç»“æ„",
                    "å®ç°å¯¹è±¡æ± "
                ]
            },
            "response_time_bottleneck": {
                "condition": lambda stats: stats.get("avg_response_time", 0) > 1000,
                "description": "å“åº”æ—¶é—´è¿‡é•¿",
                "suggestions": [
                    "ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢",
                    "æ·»åŠ ç¼“å­˜å±‚",
                    "å‡å°‘ç½‘ç»œå¾€è¿”"
                ]
            }
        }

    def analyze_bottlenecks(self) -> List[Dict[str, Any]]:
        """åˆ†ææ€§èƒ½ç“¶é¢ˆ"""
        bottlenecks = []

        # è·å–ç³»ç»ŸæŒ‡æ ‡ç»Ÿè®¡
        system_stats = {}
        for metric_name in ["cpu_usage", "memory_usage", "disk_usage"]:
            system_stats[metric_name] = self.system_monitor.get_metric_statistics(metric_name)

        # è·å–åº”ç”¨æ€§èƒ½æ‘˜è¦
        app_summary = self.app_monitor.get_performance_summary()

        # åˆå¹¶ç»Ÿè®¡æ•°æ®
        combined_stats = {**system_stats, **app_summary.get("request_statistics", {})}

        # æ£€æŸ¥æ¯ä¸ªç“¶é¢ˆè§„åˆ™
        for bottleneck_type, rule in self.bottleneck_rules.items():
            if rule["condition"](combined_stats):
                bottlenecks.append({
                    "type": bottleneck_type,
                    "description": rule["description"],
                    "suggestions": rule["suggestions"],
                    "severity": self._calculate_severity(bottleneck_type, combined_stats),
                    "detected_at": time.time()
                })

        return bottlenecks

    def _calculate_severity(self, bottleneck_type: str, stats: Dict[str, Any]) -> str:
        """è®¡ç®—ç“¶é¢ˆä¸¥é‡ç¨‹åº¦"""
        if bottleneck_type == "cpu_bottleneck":
            cpu_usage = stats.get("cpu_usage", {}).get("mean", 0)
            if cpu_usage > 95:
                return "critical"
            elif cpu_usage > 90:
                return "high"
            else:
                return "medium"

        elif bottleneck_type == "memory_bottleneck":
            memory_usage = stats.get("memory_usage", {}).get("mean", 0)
            if memory_usage > 95:
                return "critical"
            elif memory_usage > 90:
                return "high"
            else:
                return "medium"

        elif bottleneck_type == "response_time_bottleneck":
            response_time = stats.get("avg_response_time", 0)
            if response_time > 5000:
                return "critical"
            elif response_time > 2000:
                return "high"
            else:
                return "medium"

        return "low"

    def generate_optimization_report(self) -> str:
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        bottlenecks = self.analyze_bottlenecks()

        report = "=== æ€§èƒ½ç“¶é¢ˆåˆ†ææŠ¥å‘Š ===\n\n"
        report += f"åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        report += f"æ£€æµ‹åˆ° {len(bottlenecks)} ä¸ªæ€§èƒ½ç“¶é¢ˆ\n\n"

        if not bottlenecks:
            report += "âœ… æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„æ€§èƒ½ç“¶é¢ˆ\n"
            return report

        # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åº
        bottlenecks.sort(key=lambda x: {"critical": 4, "high": 3, "medium": 2, "low": 1}[x["severity"]], reverse=True)

        for i, bottleneck in enumerate(bottlenecks, 1):
            severity_emoji = {
                "critical": "ğŸ”´",
                "high": "ğŸŸ ",
                "medium": "ğŸŸ¡",
                "low": "ğŸŸ¢"
            }

            report += f"{i}. {severity_emoji[bottleneck['severity']]} {bottleneck['description']}\n"
            report += f"   ä¸¥é‡ç¨‹åº¦: {bottleneck['severity']}\n"
            report += f"   ä¼˜åŒ–å»ºè®®:\n"

            for suggestion in bottleneck['suggestions']:
                report += f"   â€¢ {suggestion}\n"

            report += "\n"

        return report


# å®æˆ˜æ¼”ç¤º
def demonstrate_performance_monitoring():
    """æ¼”ç¤ºæ€§èƒ½ç›‘æ§"""
    print("=== Chat-Roomæ€§èƒ½ç›‘æ§æ¼”ç¤º ===")

    # 1. å¯åŠ¨ç³»ç»Ÿç›‘æ§
    system_monitor = SystemMonitor(collection_interval=2.0)

    # æ·»åŠ å‘Šè­¦å›è°ƒ
    def alert_handler(alert_data):
        print(f"âš ï¸  æ€§èƒ½å‘Šè­¦: {alert_data['metric_name']} = {alert_data['current_value']:.1f} "
              f"(é˜ˆå€¼: {alert_data['threshold']})")

    system_monitor.add_alert_callback(alert_handler)
    system_monitor.start_monitoring()

    # 2. åº”ç”¨ç›‘æ§
    app_monitor = ApplicationMonitor()

    # æ¨¡æ‹Ÿä¸€äº›åº”ç”¨æ´»åŠ¨
    app_monitor.update_connection_count(25)
    app_monitor.record_request_time("send_message", 150.0)
    app_monitor.record_request_time("get_messages", 80.0)
    app_monitor.record_message("chat")
    app_monitor.record_error("connection_timeout")

    # 3. æ€§èƒ½åˆ†æ
    profiler = PerformanceProfiler()

    @profiler.profile_function("message_processing")
    def process_message(message):
        # æ¨¡æ‹Ÿæ¶ˆæ¯å¤„ç†
        time.sleep(0.01)
        return f"Processed: {message}"

    # æ‰§è¡Œä¸€äº›æ“ä½œ
    for i in range(10):
        process_message(f"message_{i}")

    # 4. ç“¶é¢ˆåˆ†æ
    time.sleep(5)  # ç­‰å¾…æ”¶é›†ä¸€äº›æ•°æ®

    analyzer = BottleneckAnalyzer(system_monitor, app_monitor)

    # è·å–æ€§èƒ½ç»Ÿè®¡
    print("\nç³»ç»Ÿæ€§èƒ½ç»Ÿè®¡:")
    for metric in ["cpu_usage", "memory_usage"]:
        stats = system_monitor.get_metric_statistics(metric)
        if stats:
            print(f"  {metric}: å¹³å‡ {stats['mean']:.1f}%, æœ€å¤§ {stats['max']:.1f}%")

    print("\nåº”ç”¨æ€§èƒ½æ‘˜è¦:")
    app_summary = app_monitor.get_performance_summary()
    print(f"  æ´»è·ƒè¿æ¥: {app_summary['active_connections']}")
    print(f"  æ€»é”™è¯¯æ•°: {app_summary['total_errors']}")

    print("\nå‡½æ•°æ€§èƒ½ç»Ÿè®¡:")
    func_stats = profiler.get_function_stats("message_processing")
    if func_stats:
        print(f"  message_processing: è°ƒç”¨ {func_stats['call_count']} æ¬¡, "
              f"å¹³å‡ {func_stats['avg_time_ms']:.2f}ms")

    # ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
    print("\n" + analyzer.generate_optimization_report())

    # åœæ­¢ç›‘æ§
    system_monitor.stop_monitoring()


if __name__ == "__main__":
    demonstrate_performance_monitoring()
```

## ğŸ“– å¯¼èˆª

â¬…ï¸ **ä¸Šä¸€èŠ‚ï¼š** [Feature Planning Analysis](feature-planning-analysis.md)

â¡ï¸ **ä¸‹ä¸€èŠ‚ï¼š** [Troubleshooting Methodology](troubleshooting-methodology.md)

ğŸ“š **è¿”å›ï¼š** [ç¬¬17ç« ï¼šé«˜çº§å®è·µ](README.md)

ğŸ  **ä¸»é¡µï¼š** [å­¦ä¹ è·¯å¾„æ€»è§ˆ](../README.md)
