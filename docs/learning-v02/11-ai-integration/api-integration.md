# APIé›†æˆåŸºç¡€

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š
- ç†è§£AI APIé›†æˆçš„åŸºæœ¬åŸç†å’Œæœ€ä½³å®è·µ
- æŒæ¡GLM-4-Flash APIçš„ä½¿ç”¨æ–¹æ³•å’Œç‰¹æ€§
- å­¦ä¼šè®¾è®¡å¯é çš„APIè°ƒç”¨å’Œé”™è¯¯å¤„ç†æœºåˆ¶
- åœ¨Chat-Roomé¡¹ç›®ä¸­å®ç°æ™ºèƒ½AIåŠ©æ‰‹åŠŸèƒ½

## ğŸ¤– AIé›†æˆæ¶æ„

### AIé›†æˆç³»ç»Ÿæ¦‚è§ˆ

```mermaid
graph TB
    subgraph "AIé›†æˆæ¶æ„"
        A[ç”¨æˆ·æ¶ˆæ¯<br/>User Message] --> B[æ¶ˆæ¯é¢„å¤„ç†<br/>Message Preprocessing]
        B --> C[AIè§¦å‘æ£€æµ‹<br/>AI Trigger Detection]
        C --> D[ä¸Šä¸‹æ–‡ç®¡ç†<br/>Context Management]
        D --> E[APIè°ƒç”¨ç®¡ç†<br/>API Call Manager]
        
        E --> F[GLM-4-Flash API<br/>GLM-4-Flash API]
        F --> G[å“åº”å¤„ç†<br/>Response Processing]
        G --> H[åå¤„ç†<br/>Post Processing]
        H --> I[æ¶ˆæ¯å‘é€<br/>Message Sending]
        
        J[é…ç½®ç®¡ç†<br/>Config Manager] --> E
        K[ç¼“å­˜ç³»ç»Ÿ<br/>Cache System] --> E
        L[é™æµæ§åˆ¶<br/>Rate Limiting] --> E
        M[é”™è¯¯å¤„ç†<br/>Error Handling] --> E
    end
    
    subgraph "AIåŠŸèƒ½æ¨¡å—"
        N[æ™ºèƒ½å›å¤<br/>Smart Reply]
        O[å†…å®¹æ€»ç»“<br/>Content Summary]
        P[è¯­è¨€ç¿»è¯‘<br/>Translation]
        Q[æƒ…æ„Ÿåˆ†æ<br/>Sentiment Analysis]
    end
    
    G --> N
    G --> O
    G --> P
    G --> Q
    
    style A fill:#e8f5e8
    style F fill:#f8d7da
    style I fill:#fff3cd
```

### APIè°ƒç”¨æµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant C as Chat-Roomå®¢æˆ·ç«¯
    participant S as Chat-RoomæœåŠ¡å™¨
    participant AI as AIç®¡ç†å™¨
    participant GLM as GLM-4-Flash API
    participant DB as æ•°æ®åº“
    
    Note over U,DB: AIåŠ©æ‰‹è°ƒç”¨æµç¨‹
    
    U->>C: å‘é€æ¶ˆæ¯ "@AI ä½ å¥½"
    C->>S: è½¬å‘æ¶ˆæ¯
    S->>AI: æ£€æµ‹AIè§¦å‘
    AI->>AI: è§£æç”¨æˆ·æ„å›¾
    AI->>DB: è·å–ä¸Šä¸‹æ–‡å†å²
    DB->>AI: è¿”å›å†å²å¯¹è¯
    
    AI->>AI: æ„å»ºAPIè¯·æ±‚
    AI->>GLM: è°ƒç”¨GLM-4-Flash API
    
    alt APIè°ƒç”¨æˆåŠŸ
        GLM->>AI: è¿”å›AIå“åº”
        AI->>AI: å¤„ç†å“åº”å†…å®¹
        AI->>S: è¿”å›å¤„ç†ç»“æœ
        S->>C: å¹¿æ’­AIå›å¤
        C->>U: æ˜¾ç¤ºAIå›å¤
        AI->>DB: ä¿å­˜å¯¹è¯è®°å½•
    else APIè°ƒç”¨å¤±è´¥
        GLM->>AI: è¿”å›é”™è¯¯ä¿¡æ¯
        AI->>AI: é”™è¯¯å¤„ç†å’Œé‡è¯•
        AI->>S: è¿”å›é”™è¯¯æç¤º
        S->>C: å‘é€é”™è¯¯æ¶ˆæ¯
    end
```

## ğŸ”Œ APIé›†æˆå®ç°

### æ™ºè°±AIå®¢æˆ·ç«¯å®ç°

```python
# server/ai/zhipu_client.py - æ™ºè°±AI APIå®¢æˆ·ç«¯
import os
import time
from typing import Dict, List, Optional, Any
from dataclasses import dataclass

try:
    from zhipuai import ZhipuAI
    ZHIPU_SDK_AVAILABLE = True
except ImportError:
    ZHIPU_SDK_AVAILABLE = False
    print("âš ï¸ æ™ºè°±AIå®˜æ–¹SDKæœªå®‰è£…ï¼Œå°†ä½¿ç”¨HTTP APIæ–¹å¼")
    print("ğŸ’¡ å»ºè®®å®‰è£…å®˜æ–¹SDK: pip install zhipuai")

    # å¤‡ç”¨HTTP APIå®ç°
    import json
    import requests

@dataclass
class AIMessage:
    """AIæ¶ˆæ¯æ•°æ®ç±»"""
    role: str  # "user", "assistant", "system"
    content: str
    timestamp: Optional[float] = None

class ZhipuClient:
    """æ™ºè°±AI APIå®¢æˆ·ç«¯"""

    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ–æ™ºè°±AIå®¢æˆ·ç«¯

        Args:
            api_key: æ™ºè°±AI APIå¯†é’¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®æ–‡ä»¶è·å–
        """
        if api_key:
            self.api_key = api_key
        else:
            # ä»é…ç½®æ–‡ä»¶è·å–APIå¯†é’¥
            try:
                from server.config.server_config import get_server_config
                server_config = get_server_config()
                self.api_key = server_config.get_ai_api_key()
            except Exception:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä»ç¯å¢ƒå˜é‡è·å–
                self.api_key = os.getenv('ZHIPU_API_KEY', '')

        if not self.api_key:
            raise ValueError("æ™ºè°±AI APIå¯†é’¥æœªè®¾ç½®")

        # æ¨¡å‹é…ç½® - ä½¿ç”¨GLM-4-Flashå…è´¹æ¨¡å‹
        self.model = "glm-4-flash"  # ä½¿ç”¨å…è´¹çš„GLM-4-Flashæ¨¡å‹
        self.max_tokens = 1024
        self.temperature = 0.7
        self.top_p = 0.9

        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        if ZHIPU_SDK_AVAILABLE:
            self.client = ZhipuAI(api_key=self.api_key)
            self.use_sdk = True
            print("âœ… ä½¿ç”¨æ™ºè°±AIå®˜æ–¹SDK")
        else:
            # å¤‡ç”¨HTTP APIé…ç½®
            self.base_url = "https://open.bigmodel.cn/api/paas/v4"
            self.headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            self.use_sdk = False
            print("âš ï¸ ä½¿ç”¨HTTP APIæ–¹å¼è°ƒç”¨æ™ºè°±AI")
    
    def chat_completion(self, messages: List[AIMessage],
                       system_prompt: str = None) -> Optional[str]:
        """
        è°ƒç”¨æ™ºè°±AIèŠå¤©å®ŒæˆAPI

        Args:
            messages: å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
            system_prompt: ç³»ç»Ÿæç¤ºè¯

        Returns:
            AIå›å¤å†…å®¹ï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        try:
            # æ„å»ºè¯·æ±‚æ¶ˆæ¯
            api_messages = []

            # æ·»åŠ ç³»ç»Ÿæç¤ºè¯
            if system_prompt:
                api_messages.append({
                    "role": "system",
                    "content": system_prompt
                })

            # æ·»åŠ å¯¹è¯æ¶ˆæ¯
            for msg in messages:
                api_messages.append({
                    "role": msg.role,
                    "content": msg.content
                })

            if self.use_sdk:
                # ä½¿ç”¨å®˜æ–¹SDKè°ƒç”¨
                return self._chat_completion_sdk(api_messages)
            else:
                # ä½¿ç”¨HTTP APIè°ƒç”¨
                return self._chat_completion_http(api_messages)

        except Exception as e:
            print(f"æ™ºè°±AI APIè°ƒç”¨é”™è¯¯: {e}")
            return None

    def _chat_completion_sdk(self, api_messages: List[Dict]) -> Optional[str]:
        """
        ä½¿ç”¨å®˜æ–¹SDKè°ƒç”¨èŠå¤©å®ŒæˆAPI

        Args:
            api_messages: APIæ¶ˆæ¯åˆ—è¡¨

        Returns:
            AIå›å¤å†…å®¹
        """
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=api_messages,
                max_tokens=self.max_tokens,
                temperature=self.temperature,
                top_p=self.top_p,
                stream=False
            )

            if response.choices and len(response.choices) > 0:
                return response.choices[0].message.content.strip()
            else:
                print("æ™ºè°±AI SDKå“åº”æ ¼å¼é”™è¯¯ï¼šæ²¡æœ‰choices")
                return None

        except Exception as e:
            print(f"æ™ºè°±AI SDKè°ƒç”¨é”™è¯¯: {e}")
            return None

    def _chat_completion_http(self, api_messages: List[Dict]) -> Optional[str]:
        """
        ä½¿ç”¨HTTP APIè°ƒç”¨èŠå¤©å®ŒæˆAPI

        Args:
            api_messages: APIæ¶ˆæ¯åˆ—è¡¨

        Returns:
            AIå›å¤å†…å®¹
        """
        try:
            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = {
                "model": self.model,
                "messages": api_messages,
                "max_tokens": self.max_tokens,
                "temperature": self.temperature,
                "top_p": self.top_p,
                "stream": False
            }

            # å‘é€è¯·æ±‚
            response = requests.post(
                f"{self.base_url}/chat/completions",
                headers=self.headers,
                json=request_data,
                timeout=30
            )

            # æ£€æŸ¥å“åº”çŠ¶æ€
            if response.status_code != 200:
                print(f"æ™ºè°±AI APIè¯·æ±‚å¤±è´¥: {response.status_code} - {response.text}")
                return None

            # è§£æå“åº”
            response_data = response.json()

            if "choices" not in response_data or not response_data["choices"]:
                print("æ™ºè°±AI APIå“åº”æ ¼å¼é”™è¯¯")
                return None

            # æå–AIå›å¤
            ai_reply = response_data["choices"][0]["message"]["content"]
            return ai_reply.strip()

        except Exception as e:
            print(f"æ™ºè°±AI HTTP APIè°ƒç”¨é”™è¯¯: {e}")
            return None

    def simple_chat(self, user_message: str, system_prompt: str = None) -> Optional[str]:
        """
        ç®€å•èŠå¤©æ¥å£

        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            system_prompt: ç³»ç»Ÿæç¤ºè¯

        Returns:
            AIå›å¤å†…å®¹
        """
        messages = [AIMessage(role="user", content=user_message, timestamp=time.time())]
        return self.chat_completion(messages, system_prompt)

    def test_connection(self) -> bool:
        """
        æµ‹è¯•APIè¿æ¥

        Returns:
            è¿æ¥æ˜¯å¦æˆåŠŸ
        """
        try:
            response = self.simple_chat("ä½ å¥½", "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œè¯·ç®€çŸ­å›å¤ã€‚")
            return response is not None and len(response.strip()) > 0
        except Exception as e:
            print(f"æ™ºè°±AIè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            return False

    def get_model_info(self) -> Dict[str, Any]:
        """
        è·å–æ¨¡å‹ä¿¡æ¯

        Returns:
            æ¨¡å‹ä¿¡æ¯å­—å…¸
        """
        return {
            "model": self.model,
            "max_tokens": self.max_tokens,
            "temperature": self.temperature,
            "top_p": self.top_p,
            "api_key_set": bool(self.api_key),
            "use_sdk": self.use_sdk,
            "sdk_available": ZHIPU_SDK_AVAILABLE
        }
# ä½¿ç”¨ç¤ºä¾‹
def demo_zhipu_client():
    """æ™ºè°±AIå®¢æˆ·ç«¯æ¼”ç¤º"""
    print("=== æ™ºè°±AIå®¢æˆ·ç«¯æ¼”ç¤º ===")

    try:
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        client = ZhipuClient()

        # æµ‹è¯•è¿æ¥
        print("æµ‹è¯•APIè¿æ¥...")
        if client.test_connection():
            print("âœ… APIè¿æ¥æˆåŠŸ")
        else:
            print("âŒ APIè¿æ¥å¤±è´¥")
            return

        # è·å–æ¨¡å‹ä¿¡æ¯
        model_info = client.get_model_info()
        print(f"æ¨¡å‹ä¿¡æ¯: {model_info}")

        # ç®€å•èŠå¤©
        print("\n--- ç®€å•èŠå¤©æµ‹è¯• ---")
        response = client.simple_chat(
            user_message="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±",
            system_prompt="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œåå«å°æ™ºã€‚è¯·ç®€çŸ­å›å¤ã€‚"
        )

        if response:
            print(f"AIå›å¤: {response}")
        else:
            print("âŒ èŠå¤©è¯·æ±‚å¤±è´¥")

        # å¸¦ä¸Šä¸‹æ–‡çš„å¯¹è¯
        print("\n--- ä¸Šä¸‹æ–‡å¯¹è¯æµ‹è¯• ---")
        messages = [
            AIMessage(role="user", content="æˆ‘å«å¼ ä¸‰"),
            AIMessage(role="assistant", content="ä½ å¥½å¼ ä¸‰ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼"),
            AIMessage(role="user", content="ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ")
        ]

        response = client.chat_completion(
            messages=messages,
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰è®°å¿†çš„AIåŠ©æ‰‹ã€‚"
        )

        if response:
            print(f"AIå›å¤ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰: {response}")
        else:
            print("âŒ ä¸Šä¸‹æ–‡å¯¹è¯å¤±è´¥")

    except Exception as e:
        print(f"æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

if __name__ == "__main__":
    demo_zhipu_client()
```

## ğŸ”§ Chat-Roomä¸­çš„AIé›†æˆ

### AIç®¡ç†å™¨å®ç°

```python
# server/ai/ai_manager.py - AIç®¡ç†å™¨
import time
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from .zhipu_client import ZhipuClient, AIMessage

@dataclass
class ChatContext:
    """èŠå¤©ä¸Šä¸‹æ–‡"""
    user_id: int
    group_id: Optional[int]
    conversation_history: List[AIMessage]
    last_interaction: float

    def add_message(self, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å†å²"""
        self.conversation_history.append(
            AIMessage(role=role, content=content, timestamp=time.time())
        )
        self.last_interaction = time.time()

        # é™åˆ¶å†å²é•¿åº¦
        if len(self.conversation_history) > 20:
            self.conversation_history = self.conversation_history[-20:]

class AIManager:
    """AIç®¡ç†å™¨ - ç®¡ç†Chat-Roomä¸­çš„AIåŠŸèƒ½"""

    def __init__(self, api_key: str = None):
        """
        åˆå§‹åŒ–AIç®¡ç†å™¨

        Args:
            api_key: æ™ºè°±AI APIå¯†é’¥
        """
        self.zhipu_client = ZhipuClient(api_key)
        self.contexts: Dict[str, ChatContext] = {}  # ç”¨æˆ·ä¸Šä¸‹æ–‡ç¼“å­˜
        self.enabled = True

        # AIé…ç½®
        self.system_prompt = """ä½ æ˜¯Chat-RoomèŠå¤©å®¤çš„AIåŠ©æ‰‹ï¼Œåå«å°æ™ºã€‚
ä½ çš„ç‰¹ç‚¹ï¼š
1. å‹å¥½ã€æœ‰å¸®åŠ©ã€æœ‰è¶£
2. å›å¤ç®€æ´æ˜äº†ï¼Œé€šå¸¸ä¸è¶…è¿‡100å­—
3. èƒ½å¤Ÿå‚ä¸ç¾¤èŠè®¨è®º
4. å¯ä»¥å›ç­”é—®é¢˜ã€æä¾›å»ºè®®
5. ä¿æŒç§¯ææ­£é¢çš„æ€åº¦

è¯·æ ¹æ®èŠå¤©å†…å®¹è‡ªç„¶åœ°å‚ä¸å¯¹è¯ã€‚"""

        # æµ‹è¯•è¿æ¥
        if not self.zhipu_client.test_connection():
            print("âš ï¸ æ™ºè°±AIè¿æ¥å¤±è´¥ï¼ŒAIåŠŸèƒ½å°†è¢«ç¦ç”¨")
            self.enabled = False
        else:
            print("âœ… æ™ºè°±AIè¿æ¥æˆåŠŸï¼ŒAIåŠŸèƒ½å·²å¯ç”¨")

    def is_enabled(self) -> bool:
        """æ£€æŸ¥AIåŠŸèƒ½æ˜¯å¦å¯ç”¨"""
        return self.enabled

    def should_respond(self, message_content: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥å“åº”æ¶ˆæ¯

        Args:
            message_content: æ¶ˆæ¯å†…å®¹

        Returns:
            æ˜¯å¦åº”è¯¥å“åº”
        """
        if not self.enabled:
            return False

        # æ£€æŸ¥æ˜¯å¦åŒ…å«@AIæ ‡è®°ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
        message_lower = message_content.lower()
        return "@ai" in message_lower or "@å°æ™º" in message_lower

    def get_context_key(self, user_id: int, group_id: Optional[int]) -> str:
        """è·å–ä¸Šä¸‹æ–‡é”®"""
        if group_id:
            return f"group_{group_id}_user_{user_id}"
        else:
            return f"private_user_{user_id}"

    def get_or_create_context(self, user_id: int, group_id: Optional[int]) -> ChatContext:
        """è·å–æˆ–åˆ›å»ºèŠå¤©ä¸Šä¸‹æ–‡"""
        context_key = self.get_context_key(user_id, group_id)

        if context_key not in self.contexts:
            self.contexts[context_key] = ChatContext(
                user_id=user_id,
                group_id=group_id,
                conversation_history=[],
                last_interaction=time.time()
            )

        return self.contexts[context_key]

    def generate_response(self, user_message: str, user_id: int,
                         group_id: Optional[int] = None,
                         username: str = None) -> Optional[str]:
        """
        ç”ŸæˆAIå“åº”

        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            user_id: ç”¨æˆ·ID
            group_id: ç¾¤ç»„IDï¼ˆç§èŠæ—¶ä¸ºNoneï¼‰
            username: ç”¨æˆ·å

        Returns:
            AIå“åº”å†…å®¹
        """
        if not self.enabled:
            return None

        try:
            # è·å–ä¸Šä¸‹æ–‡
            context = self.get_or_create_context(user_id, group_id)

            # æ¸…ç†@AIæ ‡è®°
            clean_message = user_message.replace("@AI", "").replace("@ai", "").replace("@å°æ™º", "").strip()

            # æ„å»ºæ¶ˆæ¯å†å²
            messages = context.conversation_history.copy()

            # æ·»åŠ ç”¨æˆ·åä¿¡æ¯åˆ°æ¶ˆæ¯ä¸­
            if username:
                user_message_with_name = f"{username}: {clean_message}"
            else:
                user_message_with_name = clean_message

            messages.append(AIMessage(
                role="user",
                content=user_message_with_name,
                timestamp=time.time()
            ))

            # è°ƒç”¨AI API
            ai_response = self.zhipu_client.chat_completion(
                messages=messages,
                system_prompt=self.system_prompt
            )

            if ai_response:
                # æ›´æ–°ä¸Šä¸‹æ–‡
                context.add_message("user", user_message_with_name)
                context.add_message("assistant", ai_response)

                return ai_response
            else:
                return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›å¤ï¼Œè¯·ç¨åå†è¯•ã€‚"

        except Exception as e:
            print(f"AIå“åº”ç”Ÿæˆé”™è¯¯: {e}")
            return "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ã€‚"

    def clear_context(self, user_id: int, group_id: Optional[int] = None):
        """æ¸…é™¤ç”¨æˆ·ä¸Šä¸‹æ–‡"""
        context_key = self.get_context_key(user_id, group_id)
        if context_key in self.contexts:
            del self.contexts[context_key]

    def cleanup_old_contexts(self, max_age_hours: int = 24):
        """æ¸…ç†è¿‡æœŸçš„ä¸Šä¸‹æ–‡"""
        current_time = time.time()
        max_age_seconds = max_age_hours * 3600

        expired_keys = []
        for key, context in self.contexts.items():
            if current_time - context.last_interaction > max_age_seconds:
                expired_keys.append(key)

        for key in expired_keys:
            del self.contexts[key]

        if expired_keys:
            print(f"æ¸…ç†äº† {len(expired_keys)} ä¸ªè¿‡æœŸçš„AIä¸Šä¸‹æ–‡")

    def get_stats(self) -> Dict[str, Any]:
        """è·å–AIç®¡ç†å™¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "enabled": self.enabled,
            "active_contexts": len(self.contexts),
            "model_info": self.zhipu_client.get_model_info() if self.enabled else None
        }

# ä½¿ç”¨ç¤ºä¾‹
def demo_ai_manager():
    """AIç®¡ç†å™¨æ¼”ç¤º"""
    print("=== AIç®¡ç†å™¨æ¼”ç¤º ===")

    # åˆå§‹åŒ–AIç®¡ç†å™¨
    ai_manager = AIManager()

    if not ai_manager.is_enabled():
        print("AIåŠŸèƒ½æœªå¯ç”¨ï¼Œè·³è¿‡æ¼”ç¤º")
        return

    # æ¨¡æ‹Ÿç¾¤èŠåœºæ™¯
    print("\n--- ç¾¤èŠAIå“åº”æµ‹è¯• ---")

    # ç”¨æˆ·1å‘é€æ¶ˆæ¯
    message1 = "@AI ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±"
    if ai_manager.should_respond(message1):
        response1 = ai_manager.generate_response(
            user_message=message1,
            user_id=1,
            group_id=1,
            username="å¼ ä¸‰"
        )
        print(f"ç”¨æˆ·: {message1}")
        print(f"AI: {response1}")

    # ç”¨æˆ·2å‘é€æ¶ˆæ¯
    message2 = "@AI ä½ èƒ½å¸®æˆ‘è§£ç­”ç¼–ç¨‹é—®é¢˜å—ï¼Ÿ"
    if ai_manager.should_respond(message2):
        response2 = ai_manager.generate_response(
            user_message=message2,
            user_id=2,
            group_id=1,
            username="æå››"
        )
        print(f"ç”¨æˆ·: {message2}")
        print(f"AI: {response2}")

    # æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
    stats = ai_manager.get_stats()
    print(f"\nAIç®¡ç†å™¨ç»Ÿè®¡: {stats}")

if __name__ == "__main__":
    demo_ai_manager()
```

## ğŸ¯ å®è·µç»ƒä¹ 

### ç»ƒä¹ 1ï¼šAPIé…ç½®ç®¡ç†

```python
class APIConfigManager:
    """
    APIé…ç½®ç®¡ç†ç»ƒä¹ 

    è¦æ±‚ï¼š
    1. æ”¯æŒä»é…ç½®æ–‡ä»¶åŠ è½½APIå¯†é’¥
    2. å®ç°é…ç½®éªŒè¯æœºåˆ¶
    3. æ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–
    4. æ·»åŠ é…ç½®çƒ­æ›´æ–°åŠŸèƒ½
    """

    def load_config_from_file(self, config_path: str) -> Dict[str, Any]:
        """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
        # TODO: å®ç°é…ç½®æ–‡ä»¶åŠ è½½
        pass

    def validate_config(self, config: Dict[str, Any]) -> bool:
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        # TODO: å®ç°é…ç½®éªŒè¯
        pass

    def get_api_key(self) -> str:
        """è·å–APIå¯†é’¥"""
        # TODO: å®ç°APIå¯†é’¥è·å–é€»è¾‘
        pass
```

### ç»ƒä¹ 2ï¼šAIå“åº”ç¼“å­˜

```python
class AIResponseCache:
    """
    AIå“åº”ç¼“å­˜ç»ƒä¹ 

    è¦æ±‚ï¼š
    1. å®ç°åŸºäºæ¶ˆæ¯å†…å®¹çš„ç¼“å­˜
    2. æ”¯æŒTTLè¿‡æœŸæœºåˆ¶
    3. æ·»åŠ ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡
    4. å®ç°ç¼“å­˜æ¸…ç†ç­–ç•¥
    """

    def get_cached_response(self, message_hash: str) -> Optional[str]:
        """è·å–ç¼“å­˜å“åº”"""
        # TODO: å®ç°ç¼“å­˜æŸ¥è¯¢
        pass

    def cache_response(self, message_hash: str, response: str, ttl: int = 3600):
        """ç¼“å­˜å“åº”"""
        # TODO: å®ç°å“åº”ç¼“å­˜
        pass

    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        # TODO: å®ç°ç¼“å­˜ç»Ÿè®¡
        pass
## âœ… å­¦ä¹ æ£€æŸ¥

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œè¯·ç¡®è®¤æ‚¨èƒ½å¤Ÿï¼š

- [ ] ç†è§£æ™ºè°±AI APIé›†æˆçš„åŸºæœ¬æ¶æ„
- [ ] é…ç½®å’Œä½¿ç”¨GLM-4-Flashå…è´¹æ¨¡å‹
- [ ] å®ç°åŒæ­¥APIè°ƒç”¨å’Œé”™è¯¯å¤„ç†
- [ ] è®¾è®¡AIç®¡ç†å™¨ç®¡ç†èŠå¤©ä¸Šä¸‹æ–‡
- [ ] åœ¨Chat-Roomä¸­é›†æˆAIåŠŸèƒ½
- [ ] å®Œæˆå®è·µç»ƒä¹ 

## ğŸ“š ä¸‹ä¸€æ­¥

APIé›†æˆåŸºç¡€æŒæ¡åï¼Œè¯·ç»§ç»­å­¦ä¹ ï¼š
- [GLM-4-Flashç‰¹æ€§](glm-4-flash-features.md)
- [ä¸Šä¸‹æ–‡ç®¡ç†](context-management.md)
- [AIå“åº”ä¼˜åŒ–](ai-response-optimization.md)

---

**ç°åœ¨æ‚¨å·²ç»æŒæ¡äº†æ™ºè°±AI APIé›†æˆçš„æ ¸å¿ƒæŠ€æœ¯ï¼** ğŸ¤–
    
    def _build_request(self, messages: List[ChatMessage], stream: bool) -> Dict[str, Any]:
        """æ„å»ºAPIè¯·æ±‚"""
        return {
            "model": self.config.model,
            "messages": [msg.to_dict() for msg in messages],
            "max_tokens": self.config.max_tokens,
            "temperature": self.config.temperature,
            "top_p": self.config.top_p,
            "stream": stream
        }
    
    async def _make_request(self, request_data: Dict[str, Any], 
                          stream: bool) -> APIResponse:
        """æ‰§è¡ŒAPIè¯·æ±‚"""
        headers = {
            "Authorization": f"Bearer {self.config.api_key}",
            "Content-Type": "application/json"
        }
        
        url = f"{self.config.base_url}/chat/completions"
        
        for attempt in range(self.config.max_retries):
            try:
                async with self.session.post(url, json=request_data, headers=headers) as response:
                    if response.status == 200:
                        if stream:
                            return await self._handle_stream_response(response)
                        else:
                            return await self._handle_normal_response(response)
                    else:
                        error_text = await response.text()
                        self.logger.warning(f"APIè¯·æ±‚å¤±è´¥ (çŠ¶æ€ç : {response.status}): {error_text}")
                        
                        if attempt < self.config.max_retries - 1:
                            await asyncio.sleep(self.config.retry_delay * (2 ** attempt))
                            continue
                        
                        return APIResponse(
                            success=False,
                            error_message=f"HTTP {response.status}: {error_text}",
                            error_code=str(response.status)
                        )
            
            except asyncio.TimeoutError:
                self.logger.warning(f"APIè¯·æ±‚è¶…æ—¶ (å°è¯• {attempt + 1}/{self.config.max_retries})")
                if attempt < self.config.max_retries - 1:
                    await asyncio.sleep(self.config.retry_delay * (2 ** attempt))
                    continue
                
                return APIResponse(
                    success=False,
                    error_message="è¯·æ±‚è¶…æ—¶",
                    error_code="TIMEOUT"
                )
            
            except Exception as e:
                self.logger.error(f"APIè¯·æ±‚å¼‚å¸¸ (å°è¯• {attempt + 1}/{self.config.max_retries}): {e}")
                if attempt < self.config.max_retries - 1:
                    await asyncio.sleep(self.config.retry_delay * (2 ** attempt))
                    continue
                
                return APIResponse(
                    success=False,
                    error_message=str(e),
                    error_code="REQUEST_ERROR"
                )
        
        return APIResponse(
            success=False,
            error_message="æ‰€æœ‰é‡è¯•å°è¯•éƒ½å¤±è´¥äº†",
            error_code="MAX_RETRIES_EXCEEDED"
        )
    
    async def _handle_normal_response(self, response: aiohttp.ClientResponse) -> APIResponse:
        """å¤„ç†æ™®é€šå“åº”"""
        try:
            data = await response.json()
            
            if "choices" in data and len(data["choices"]) > 0:
                content = data["choices"][0]["message"]["content"]
                usage = data.get("usage", {})
                
                return APIResponse(
                    success=True,
                    content=content,
                    usage=usage
                )
            else:
                return APIResponse(
                    success=False,
                    error_message="å“åº”æ ¼å¼é”™è¯¯ï¼šç¼ºå°‘choiceså­—æ®µ",
                    error_code="INVALID_RESPONSE"
                )
        
        except json.JSONDecodeError as e:
            return APIResponse(
                success=False,
                error_message=f"JSONè§£æé”™è¯¯: {e}",
                error_code="JSON_DECODE_ERROR"
            )
    
    async def _handle_stream_response(self, response: aiohttp.ClientResponse) -> APIResponse:
        """å¤„ç†æµå¼å“åº”"""
        content_parts = []
        
        try:
            async for line in response.content:
                line = line.decode('utf-8').strip()
                
                if line.startswith('data: '):
                    data_str = line[6:]  # ç§»é™¤ 'data: ' å‰ç¼€
                    
                    if data_str == '[DONE]':
                        break
                    
                    try:
                        data = json.loads(data_str)
                        if "choices" in data and len(data["choices"]) > 0:
                            delta = data["choices"][0].get("delta", {})
                            if "content" in delta:
                                content_parts.append(delta["content"])
                    except json.JSONDecodeError:
                        continue
            
            full_content = ''.join(content_parts)
            
            return APIResponse(
                success=True,
                content=full_content
            )
        
        except Exception as e:
            return APIResponse(
                success=False,
                error_message=f"æµå¼å“åº”å¤„ç†é”™è¯¯: {e}",
                error_code="STREAM_ERROR"
            )
    
    async def _wait_for_rate_limit(self):
        """ç­‰å¾…é™æµ"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < self.min_request_interval:
            await asyncio.sleep(self.min_request_interval - time_since_last)
        
        self.last_request_time = time.time()
    
    def _update_stats(self, response: APIResponse):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        self.stats['total_requests'] += 1
        
        if response.success:
            self.stats['successful_requests'] += 1
            if response.usage:
                self.stats['total_tokens_used'] += response.usage.get('total_tokens', 0)
        else:
            self.stats['failed_requests'] += 1
        
        if response.response_time:
            self.stats['total_response_time'] += response.response_time
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.stats.copy()
        
        if stats['total_requests'] > 0:
            stats['success_rate'] = stats['successful_requests'] / stats['total_requests']
            stats['average_response_time'] = stats['total_response_time'] / stats['total_requests']
        else:
            stats['success_rate'] = 0.0
            stats['average_response_time'] = 0.0
        
        return stats

# ä½¿ç”¨ç¤ºä¾‹
async def demo_glm_client():
    """GLMå®¢æˆ·ç«¯æ¼”ç¤º"""
    # é…ç½®ï¼ˆå®é™…ä½¿ç”¨æ—¶éœ€è¦çœŸå®çš„APIå¯†é’¥ï¼‰
    config = GLMConfig(
        api_key="your_api_key_here",
        model="glm-4-flash",
        max_tokens=512,
        temperature=0.7
    )
    
    print("=== GLM-4-Flash APIå®¢æˆ·ç«¯æ¼”ç¤º ===")
    
    async with GLMClient(config) as client:
        # ç®€å•èŠå¤©
        response = await client.simple_chat(
            user_message="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±",
            system_prompt="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œåå«å°æ™ºã€‚"
        )
        
        if response.success:
            print(f"AIå›å¤: {response.content}")
            print(f"å“åº”æ—¶é—´: {response.response_time:.2f}ç§’")
            if response.usage:
                print(f"Tokenä½¿ç”¨: {response.usage}")
        else:
            print(f"è¯·æ±‚å¤±è´¥: {response.error_message}")
        
        # å¸¦ä¸Šä¸‹æ–‡çš„å¯¹è¯
        history = [
            ChatMessage(MessageRole.USER, "æˆ‘å«å¼ ä¸‰"),
            ChatMessage(MessageRole.ASSISTANT, "ä½ å¥½å¼ ä¸‰ï¼Œå¾ˆé«˜å…´è®¤è¯†ä½ ï¼")
        ]
        
        response = await client.chat_with_context(
            user_message="ä½ è¿˜è®°å¾—æˆ‘çš„åå­—å—ï¼Ÿ",
            conversation_history=history,
            system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰è®°å¿†çš„AIåŠ©æ‰‹ã€‚"
        )
        
        if response.success:
            print(f"AIå›å¤ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰: {response.content}")
        
        # æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
        stats = client.get_stats()
        print(f"APIè°ƒç”¨ç»Ÿè®¡: {stats}")

if __name__ == "__main__":
    asyncio.run(demo_glm_client())
```

## ğŸ¯ å®è·µç»ƒä¹ 

### ç»ƒä¹ 1ï¼šAPIé…ç½®ç®¡ç†
```python
class APIConfigManager:
    """
    APIé…ç½®ç®¡ç†ç»ƒä¹ 
    
    è¦æ±‚ï¼š
    1. æ”¯æŒå¤šä¸ªAPIæä¾›å•†é…ç½®
    2. å®ç°é…ç½®çƒ­æ›´æ–°
    3. æ·»åŠ é…ç½®éªŒè¯æœºåˆ¶
    4. æ”¯æŒç¯å¢ƒå˜é‡è¦†ç›–
    """
    
    def load_config_from_file(self, config_path: str) -> GLMConfig:
        """ä»æ–‡ä»¶åŠ è½½é…ç½®"""
        # TODO: å®ç°é…ç½®æ–‡ä»¶åŠ è½½
        pass
    
    def validate_config(self, config: GLMConfig) -> bool:
        """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
        # TODO: å®ç°é…ç½®éªŒè¯
        pass
```

### ç»ƒä¹ 2ï¼šAPIå“åº”ç¼“å­˜
```python
class APIResponseCache:
    """
    APIå“åº”ç¼“å­˜ç»ƒä¹ 
    
    è¦æ±‚ï¼š
    1. å®ç°åŸºäºå†…å®¹å“ˆå¸Œçš„ç¼“å­˜
    2. æ”¯æŒTTLè¿‡æœŸæœºåˆ¶
    3. æ·»åŠ ç¼“å­˜å‘½ä¸­ç‡ç»Ÿè®¡
    4. å®ç°ç¼“å­˜æ¸…ç†ç­–ç•¥
    """
    
    def get_cached_response(self, request_hash: str) -> Optional[APIResponse]:
        """è·å–ç¼“å­˜å“åº”"""
        # TODO: å®ç°ç¼“å­˜æŸ¥è¯¢
        pass
    
    def cache_response(self, request_hash: str, response: APIResponse):
        """ç¼“å­˜å“åº”"""
        # TODO: å®ç°å“åº”ç¼“å­˜
        pass
```

## âœ… å­¦ä¹ æ£€æŸ¥

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œè¯·ç¡®è®¤æ‚¨èƒ½å¤Ÿï¼š

- [ ] ç†è§£AI APIé›†æˆçš„åŸºæœ¬æ¶æ„
- [ ] é…ç½®å’Œä½¿ç”¨GLM-4-Flash API
- [ ] å®ç°å¼‚æ­¥APIè°ƒç”¨å’Œé”™è¯¯å¤„ç†
- [ ] è®¾è®¡é™æµå’Œé‡è¯•æœºåˆ¶
- [ ] ç®¡ç†APIè°ƒç”¨ç»Ÿè®¡å’Œç›‘æ§
- [ ] å®Œæˆå®è·µç»ƒä¹ 

## ğŸ“š ä¸‹ä¸€æ­¥

APIé›†æˆåŸºç¡€æŒæ¡åï¼Œè¯·ç»§ç»­å­¦ä¹ ï¼š
- [GLM-4-Flashç‰¹æ€§](glm-4-flash-features.md)
- [ä¸Šä¸‹æ–‡ç®¡ç†](context-management.md)
- [å¼‚æ­¥å¤„ç†](async-processing.md)

---

**ç°åœ¨æ‚¨å·²ç»æŒæ¡äº†AI APIé›†æˆçš„æ ¸å¿ƒæŠ€æœ¯ï¼** ğŸ¤–
