# å¼‚æ­¥å¤„ç†æœºåˆ¶

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š
- ç†è§£AIé›†æˆä¸­å¼‚æ­¥å¤„ç†çš„é‡è¦æ€§å’Œä¼˜åŠ¿
- æŒæ¡å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—å’Œå¹¶å‘æ§åˆ¶æŠ€æœ¯
- å­¦ä¼šè®¾è®¡é«˜æ€§èƒ½çš„AIæœåŠ¡æ¶æ„
- åœ¨Chat-Roomé¡¹ç›®ä¸­å®ç°æµç•…çš„AIäº¤äº’ä½“éªŒ

## âš¡ å¼‚æ­¥å¤„ç†æ¶æ„

### å¼‚æ­¥AIå¤„ç†ç³»ç»Ÿæ¦‚è§ˆ

```mermaid
graph TB
    subgraph "å¼‚æ­¥AIå¤„ç†ç³»ç»Ÿ"
        A[ç”¨æˆ·è¯·æ±‚<br/>User Request] --> B[è¯·æ±‚éªŒè¯<br/>Request Validation]
        B --> C[ä»»åŠ¡é˜Ÿåˆ—<br/>Task Queue]
        C --> D[ä»»åŠ¡è°ƒåº¦å™¨<br/>Task Scheduler]
        D --> E[AIå·¥ä½œæ± <br/>AI Worker Pool]
        
        E --> F[APIè°ƒç”¨<br/>API Call]
        F --> G[å“åº”å¤„ç†<br/>Response Processing]
        G --> H[ç»“æœç¼“å­˜<br/>Result Cache]
        H --> I[æ¶ˆæ¯æ¨é€<br/>Message Push]
        
        J[è´Ÿè½½å‡è¡¡<br/>Load Balancer] --> E
        K[ç›‘æ§ç³»ç»Ÿ<br/>Monitoring] --> D
        L[é”™è¯¯å¤„ç†<br/>Error Handler] --> G
        M[é‡è¯•æœºåˆ¶<br/>Retry Logic] --> F
    end
    
    subgraph "å¼‚æ­¥ç»„ä»¶"
        N[ä»»åŠ¡é˜Ÿåˆ—<br/>Redis/RabbitMQ]
        O[WebSocket<br/>Real-time Push]
        P[ç¼“å­˜å±‚<br/>Cache Layer]
        Q[æ•°æ®åº“<br/>Database]
    end
    
    C --> N
    I --> O
    H --> P
    G --> Q
    
    style A fill:#e8f5e8
    style I fill:#f8d7da
```

### å¼‚æ­¥å¤„ç†æµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant C as å®¢æˆ·ç«¯
    participant S as æœåŠ¡å™¨
    participant Q as ä»»åŠ¡é˜Ÿåˆ—
    participant W as AIå·¥ä½œå™¨
    participant AI as AI API
    participant WS as WebSocket
    
    Note over U,WS: å¼‚æ­¥AIå¤„ç†æµç¨‹
    
    U->>C: å‘é€AIè¯·æ±‚
    C->>S: æäº¤è¯·æ±‚
    S->>S: ç”Ÿæˆä»»åŠ¡ID
    S->>Q: åŠ å…¥ä»»åŠ¡é˜Ÿåˆ—
    S->>C: è¿”å›ä»»åŠ¡ID
    C->>U: æ˜¾ç¤º"å¤„ç†ä¸­..."
    
    Q->>W: åˆ†é…ä»»åŠ¡
    W->>AI: è°ƒç”¨AI API
    
    alt APIè°ƒç”¨æˆåŠŸ
        AI->>W: è¿”å›AIå“åº”
        W->>S: å¤„ç†å®Œæˆ
        S->>WS: æ¨é€ç»“æœ
        WS->>C: å®æ—¶æ›´æ–°
        C->>U: æ˜¾ç¤ºAIå›å¤
    else APIè°ƒç”¨å¤±è´¥
        AI->>W: è¿”å›é”™è¯¯
        W->>W: é‡è¯•é€»è¾‘
        alt é‡è¯•æˆåŠŸ
            W->>S: å¤„ç†å®Œæˆ
        else é‡è¯•å¤±è´¥
            W->>S: å¤„ç†å¤±è´¥
            S->>WS: æ¨é€é”™è¯¯
            WS->>C: æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        end
    end
```

## ğŸ”„ å¼‚æ­¥å¤„ç†å®ç°

### å¼‚æ­¥AIä»»åŠ¡ç®¡ç†å™¨

```python
# server/ai/async_processor.py - å¼‚æ­¥AIå¤„ç†å™¨
import asyncio
import json
import time
import uuid
from typing import Dict, List, Optional, Any, Callable, Coroutine
from dataclasses import dataclass, asdict
from enum import Enum
import aioredis
import logging
from concurrent.futures import ThreadPoolExecutor

class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€"""
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"
    RETRYING = "retrying"

class TaskPriority(Enum):
    """ä»»åŠ¡ä¼˜å…ˆçº§"""
    LOW = 1
    NORMAL = 2
    HIGH = 3
    URGENT = 4

@dataclass
class AITask:
    """AIä»»åŠ¡"""
    task_id: str
    user_id: int
    request_type: str
    request_data: Dict[str, Any]
    priority: TaskPriority = TaskPriority.NORMAL
    status: TaskStatus = TaskStatus.PENDING
    created_at: float = None
    started_at: Optional[float] = None
    completed_at: Optional[float] = None
    result: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None
    retry_count: int = 0
    max_retries: int = 3
    timeout: float = 30.0
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = time.time()
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        data = asdict(self)
        data['priority'] = self.priority.value
        data['status'] = self.status.value
        return data
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'AITask':
        """ä»å­—å…¸åˆ›å»º"""
        data['priority'] = TaskPriority(data['priority'])
        data['status'] = TaskStatus(data['status'])
        return cls(**data)

class AsyncAIProcessor:
    """
    å¼‚æ­¥AIå¤„ç†å™¨
    
    åŠŸèƒ½ï¼š
    1. å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ç®¡ç†
    2. å¹¶å‘AI APIè°ƒç”¨
    3. å®æ—¶ç»“æœæ¨é€
    4. é”™è¯¯å¤„ç†å’Œé‡è¯•
    5. æ€§èƒ½ç›‘æ§å’Œä¼˜åŒ–
    """
    
    def __init__(self, redis_url: str = "redis://localhost:6379",
                 max_workers: int = 10, max_concurrent_tasks: int = 50):
        self.redis_url = redis_url
        self.max_workers = max_workers
        self.max_concurrent_tasks = max_concurrent_tasks
        
        # Redisè¿æ¥
        self.redis: Optional[aioredis.Redis] = None
        
        # ä»»åŠ¡ç®¡ç†
        self.active_tasks: Dict[str, AITask] = {}
        self.task_semaphore = asyncio.Semaphore(max_concurrent_tasks)
        
        # å·¥ä½œå™¨ç®¡ç†
        self.workers: List[asyncio.Task] = []
        self.worker_pool = ThreadPoolExecutor(max_workers=max_workers)
        
        # äº‹ä»¶å›è°ƒ
        self.task_callbacks: Dict[str, List[Callable]] = {
            'task_started': [],
            'task_completed': [],
            'task_failed': [],
            'task_progress': []
        }
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_tasks': 0,
            'completed_tasks': 0,
            'failed_tasks': 0,
            'average_processing_time': 0.0,
            'current_queue_size': 0
        }
        
        self.logger = logging.getLogger('AsyncAIProcessor')
        self.running = False
    
    async def start(self):
        """å¯åŠ¨å¼‚æ­¥å¤„ç†å™¨"""
        if self.running:
            return
        
        # è¿æ¥Redis
        self.redis = await aioredis.from_url(self.redis_url)
        
        # å¯åŠ¨å·¥ä½œå™¨
        for i in range(self.max_workers):
            worker = asyncio.create_task(self._worker_loop(f"worker-{i}"))
            self.workers.append(worker)
        
        # å¯åŠ¨ç›‘æ§ä»»åŠ¡
        asyncio.create_task(self._monitor_loop())
        
        self.running = True
        self.logger.info(f"å¼‚æ­¥AIå¤„ç†å™¨å·²å¯åŠ¨ï¼Œå·¥ä½œå™¨æ•°é‡: {self.max_workers}")
    
    async def stop(self):
        """åœæ­¢å¼‚æ­¥å¤„ç†å™¨"""
        if not self.running:
            return
        
        self.running = False
        
        # åœæ­¢å·¥ä½œå™¨
        for worker in self.workers:
            worker.cancel()
        
        # ç­‰å¾…å·¥ä½œå™¨ç»“æŸ
        await asyncio.gather(*self.workers, return_exceptions=True)
        
        # å…³é—­Redisè¿æ¥
        if self.redis:
            await self.redis.close()
        
        # å…³é—­çº¿ç¨‹æ± 
        self.worker_pool.shutdown(wait=True)
        
        self.logger.info("å¼‚æ­¥AIå¤„ç†å™¨å·²åœæ­¢")
    
    async def submit_task(self, user_id: int, request_type: str,
                         request_data: Dict[str, Any], 
                         priority: TaskPriority = TaskPriority.NORMAL,
                         timeout: float = 30.0) -> str:
        """
        æäº¤AIä»»åŠ¡
        
        Args:
            user_id: ç”¨æˆ·ID
            request_type: è¯·æ±‚ç±»å‹
            request_data: è¯·æ±‚æ•°æ®
            priority: ä»»åŠ¡ä¼˜å…ˆçº§
            timeout: è¶…æ—¶æ—¶é—´
            
        Returns:
            ä»»åŠ¡ID
        """
        # ç”Ÿæˆä»»åŠ¡ID
        task_id = str(uuid.uuid4())
        
        # åˆ›å»ºä»»åŠ¡
        task = AITask(
            task_id=task_id,
            user_id=user_id,
            request_type=request_type,
            request_data=request_data,
            priority=priority,
            timeout=timeout
        )
        
        # æ·»åŠ åˆ°Redisé˜Ÿåˆ—
        queue_name = f"ai_tasks:{priority.name.lower()}"
        await self.redis.lpush(queue_name, json.dumps(task.to_dict()))
        
        # æ›´æ–°ç»Ÿè®¡
        self.stats['total_tasks'] += 1
        self.stats['current_queue_size'] = await self._get_queue_size()
        
        self.logger.info(f"ä»»åŠ¡å·²æäº¤: {task_id}, ç±»å‹: {request_type}, ç”¨æˆ·: {user_id}")
        return task_id
    
    async def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        # å…ˆæ£€æŸ¥æ´»è·ƒä»»åŠ¡
        if task_id in self.active_tasks:
            return self.active_tasks[task_id].to_dict()
        
        # ä»Redisè·å–
        task_data = await self.redis.get(f"task_result:{task_id}")
        if task_data:
            return json.loads(task_data)
        
        return None
    
    async def cancel_task(self, task_id: str) -> bool:
        """å–æ¶ˆä»»åŠ¡"""
        # æ£€æŸ¥æ´»è·ƒä»»åŠ¡
        if task_id in self.active_tasks:
            task = self.active_tasks[task_id]
            task.status = TaskStatus.CANCELLED
            return True
        
        # ä»é˜Ÿåˆ—ä¸­ç§»é™¤ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
        return False
    
    def add_callback(self, event_type: str, callback: Callable):
        """æ·»åŠ äº‹ä»¶å›è°ƒ"""
        if event_type in self.task_callbacks:
            self.task_callbacks[event_type].append(callback)
    
    async def _worker_loop(self, worker_name: str):
        """å·¥ä½œå™¨ä¸»å¾ªç¯"""
        self.logger.info(f"å·¥ä½œå™¨ {worker_name} å·²å¯åŠ¨")
        
        while self.running:
            try:
                # è·å–ä»»åŠ¡ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰
                task = await self._get_next_task()
                if not task:
                    await asyncio.sleep(0.1)
                    continue
                
                # å¤„ç†ä»»åŠ¡
                async with self.task_semaphore:
                    await self._process_task(task, worker_name)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                self.logger.error(f"å·¥ä½œå™¨ {worker_name} å¼‚å¸¸: {e}")
                await asyncio.sleep(1)
        
        self.logger.info(f"å·¥ä½œå™¨ {worker_name} å·²åœæ­¢")
    
    async def _get_next_task(self) -> Optional[AITask]:
        """è·å–ä¸‹ä¸€ä¸ªä»»åŠ¡"""
        # æŒ‰ä¼˜å…ˆçº§é¡ºåºæ£€æŸ¥é˜Ÿåˆ—
        for priority in [TaskPriority.URGENT, TaskPriority.HIGH, 
                        TaskPriority.NORMAL, TaskPriority.LOW]:
            queue_name = f"ai_tasks:{priority.name.lower()}"
            
            task_data = await self.redis.brpop(queue_name, timeout=1)
            if task_data:
                task_dict = json.loads(task_data[1])
                return AITask.from_dict(task_dict)
        
        return None
    
    async def _process_task(self, task: AITask, worker_name: str):
        """å¤„ç†å•ä¸ªä»»åŠ¡"""
        task.status = TaskStatus.PROCESSING
        task.started_at = time.time()
        self.active_tasks[task.task_id] = task
        
        # è§¦å‘å¼€å§‹äº‹ä»¶
        await self._trigger_event('task_started', task)
        
        try:
            # æ ¹æ®è¯·æ±‚ç±»å‹å¤„ç†ä»»åŠ¡
            if task.request_type == "chat_completion":
                result = await self._process_chat_completion(task)
            elif task.request_type == "content_summary":
                result = await self._process_content_summary(task)
            elif task.request_type == "translation":
                result = await self._process_translation(task)
            else:
                raise ValueError(f"æœªçŸ¥çš„è¯·æ±‚ç±»å‹: {task.request_type}")
            
            # ä»»åŠ¡å®Œæˆ
            task.status = TaskStatus.COMPLETED
            task.completed_at = time.time()
            task.result = result
            
            # ä¿å­˜ç»“æœåˆ°Redis
            await self._save_task_result(task)
            
            # è§¦å‘å®Œæˆäº‹ä»¶
            await self._trigger_event('task_completed', task)
            
            # æ›´æ–°ç»Ÿè®¡
            self.stats['completed_tasks'] += 1
            processing_time = task.completed_at - task.started_at
            self._update_average_processing_time(processing_time)
            
            self.logger.info(f"ä»»åŠ¡å®Œæˆ: {task.task_id}, è€—æ—¶: {processing_time:.2f}s")
        
        except Exception as e:
            # ä»»åŠ¡å¤±è´¥
            task.status = TaskStatus.FAILED
            task.error_message = str(e)
            task.completed_at = time.time()
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡è¯•
            if task.retry_count < task.max_retries:
                task.retry_count += 1
                task.status = TaskStatus.RETRYING
                
                # é‡æ–°åŠ å…¥é˜Ÿåˆ—
                queue_name = f"ai_tasks:{task.priority.name.lower()}"
                await self.redis.lpush(queue_name, json.dumps(task.to_dict()))
                
                self.logger.warning(f"ä»»åŠ¡é‡è¯•: {task.task_id}, é‡è¯•æ¬¡æ•°: {task.retry_count}")
            else:
                # è§¦å‘å¤±è´¥äº‹ä»¶
                await self._trigger_event('task_failed', task)
                
                # æ›´æ–°ç»Ÿè®¡
                self.stats['failed_tasks'] += 1
                
                self.logger.error(f"ä»»åŠ¡å¤±è´¥: {task.task_id}, é”™è¯¯: {e}")
        
        finally:
            # ä»æ´»è·ƒä»»åŠ¡ä¸­ç§»é™¤
            if task.task_id in self.active_tasks:
                del self.active_tasks[task.task_id]
    
    async def _process_chat_completion(self, task: AITask) -> Dict[str, Any]:
        """å¤„ç†èŠå¤©å®Œæˆä»»åŠ¡"""
        # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„AI API
        # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿä¸€ä¸ªå¼‚æ­¥APIè°ƒç”¨
        
        await asyncio.sleep(1)  # æ¨¡æ‹ŸAPIè°ƒç”¨å»¶è¿Ÿ
        
        return {
            "response": f"è¿™æ˜¯å¯¹ç”¨æˆ·{task.user_id}æ¶ˆæ¯çš„AIå›å¤",
            "tokens_used": 150,
            "model": "glm-4-flash"
        }
    
    async def _process_content_summary(self, task: AITask) -> Dict[str, Any]:
        """å¤„ç†å†…å®¹æ€»ç»“ä»»åŠ¡"""
        await asyncio.sleep(0.5)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        return {
            "summary": "è¿™æ˜¯å†…å®¹æ€»ç»“",
            "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"],
            "tokens_used": 80
        }
    
    async def _process_translation(self, task: AITask) -> Dict[str, Any]:
        """å¤„ç†ç¿»è¯‘ä»»åŠ¡"""
        await asyncio.sleep(0.3)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        
        return {
            "translated_text": "è¿™æ˜¯ç¿»è¯‘ç»“æœ",
            "source_language": "zh",
            "target_language": "en",
            "confidence": 0.95
        }
    
    async def _save_task_result(self, task: AITask):
        """ä¿å­˜ä»»åŠ¡ç»“æœ"""
        result_key = f"task_result:{task.task_id}"
        result_data = json.dumps(task.to_dict())
        
        # è®¾ç½®è¿‡æœŸæ—¶é—´ï¼ˆ1å°æ—¶ï¼‰
        await self.redis.setex(result_key, 3600, result_data)
    
    async def _trigger_event(self, event_type: str, task: AITask):
        """è§¦å‘äº‹ä»¶å›è°ƒ"""
        for callback in self.task_callbacks.get(event_type, []):
            try:
                if asyncio.iscoroutinefunction(callback):
                    await callback(task)
                else:
                    callback(task)
            except Exception as e:
                self.logger.error(f"äº‹ä»¶å›è°ƒå¼‚å¸¸: {e}")
    
    async def _get_queue_size(self) -> int:
        """è·å–é˜Ÿåˆ—å¤§å°"""
        total_size = 0
        for priority in TaskPriority:
            queue_name = f"ai_tasks:{priority.name.lower()}"
            size = await self.redis.llen(queue_name)
            total_size += size
        return total_size
    
    def _update_average_processing_time(self, processing_time: float):
        """æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´"""
        completed = self.stats['completed_tasks']
        if completed == 1:
            self.stats['average_processing_time'] = processing_time
        else:
            current_avg = self.stats['average_processing_time']
            self.stats['average_processing_time'] = (current_avg * (completed - 1) + processing_time) / completed
    
    async def _monitor_loop(self):
        """ç›‘æ§å¾ªç¯"""
        while self.running:
            try:
                # æ›´æ–°é˜Ÿåˆ—å¤§å°ç»Ÿè®¡
                self.stats['current_queue_size'] = await self._get_queue_size()
                
                # è®°å½•ç»Ÿè®¡ä¿¡æ¯
                if self.stats['total_tasks'] % 100 == 0 and self.stats['total_tasks'] > 0:
                    self.logger.info(f"å¤„ç†ç»Ÿè®¡: {self.stats}")
                
                await asyncio.sleep(10)  # æ¯10ç§’ç›‘æ§ä¸€æ¬¡
                
            except Exception as e:
                self.logger.error(f"ç›‘æ§å¾ªç¯å¼‚å¸¸: {e}")
                await asyncio.sleep(5)
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.stats.copy()
        stats['active_tasks_count'] = len(self.active_tasks)
        stats['worker_count'] = len(self.workers)
        
        if stats['total_tasks'] > 0:
            stats['success_rate'] = stats['completed_tasks'] / stats['total_tasks']
            stats['failure_rate'] = stats['failed_tasks'] / stats['total_tasks']
        else:
            stats['success_rate'] = 0.0
            stats['failure_rate'] = 0.0
        
        return stats

# ä½¿ç”¨ç¤ºä¾‹
async def demo_async_processor():
    """å¼‚æ­¥å¤„ç†å™¨æ¼”ç¤º"""
    processor = AsyncAIProcessor(max_workers=3)
    
    # æ·»åŠ äº‹ä»¶å›è°ƒ
    async def on_task_completed(task: AITask):
        print(f"ä»»åŠ¡å®Œæˆ: {task.task_id}, ç»“æœ: {task.result}")
    
    def on_task_failed(task: AITask):
        print(f"ä»»åŠ¡å¤±è´¥: {task.task_id}, é”™è¯¯: {task.error_message}")
    
    processor.add_callback('task_completed', on_task_completed)
    processor.add_callback('task_failed', on_task_failed)
    
    print("=== å¼‚æ­¥AIå¤„ç†å™¨æ¼”ç¤º ===")
    
    try:
        # å¯åŠ¨å¤„ç†å™¨
        await processor.start()
        
        # æäº¤ä»»åŠ¡
        tasks = []
        for i in range(5):
            task_id = await processor.submit_task(
                user_id=i + 1,
                request_type="chat_completion",
                request_data={"message": f"æµ‹è¯•æ¶ˆæ¯ {i + 1}"},
                priority=TaskPriority.NORMAL
            )
            tasks.append(task_id)
            print(f"æäº¤ä»»åŠ¡: {task_id}")
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        await asyncio.sleep(5)
        
        # æŸ¥çœ‹ä»»åŠ¡çŠ¶æ€
        for task_id in tasks:
            status = await processor.get_task_status(task_id)
            if status:
                print(f"ä»»åŠ¡ {task_id}: {status['status']}")
        
        # æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯
        stats = processor.get_stats()
        print(f"å¤„ç†ç»Ÿè®¡: {stats}")
        
    finally:
        # åœæ­¢å¤„ç†å™¨
        await processor.stop()

if __name__ == "__main__":
    asyncio.run(demo_async_processor())
```

## ğŸ¯ å®è·µç»ƒä¹ 

### ç»ƒä¹ 1ï¼šæµå¼å“åº”å¤„ç†
```python
class StreamingResponseHandler:
    """
    æµå¼å“åº”å¤„ç†ç»ƒä¹ 
    
    è¦æ±‚ï¼š
    1. å®ç°AIæµå¼å“åº”çš„å®æ—¶æ¨é€
    2. æ”¯æŒéƒ¨åˆ†ç»“æœçš„å¢é‡æ›´æ–°
    3. å¤„ç†æµå¼å“åº”çš„é”™è¯¯å’Œä¸­æ–­
    4. ä¼˜åŒ–ç”¨æˆ·ä½“éªŒå’Œå“åº”é€Ÿåº¦
    """
    
    async def handle_streaming_response(self, task_id: str, response_stream):
        """å¤„ç†æµå¼å“åº”"""
        # TODO: å®ç°æµå¼å“åº”å¤„ç†
        pass
```

### ç»ƒä¹ 2ï¼šæ™ºèƒ½ä»»åŠ¡è°ƒåº¦
```python
class IntelligentTaskScheduler:
    """
    æ™ºèƒ½ä»»åŠ¡è°ƒåº¦ç»ƒä¹ 
    
    è¦æ±‚ï¼š
    1. åŸºäºç”¨æˆ·ä¼˜å…ˆçº§å’Œå†å²è¡Œä¸ºè°ƒåº¦ä»»åŠ¡
    2. å®ç°åŠ¨æ€è´Ÿè½½å‡è¡¡
    3. æ”¯æŒä»»åŠ¡ä¾èµ–å’Œæ‰¹å¤„ç†
    4. ä¼˜åŒ–èµ„æºåˆ©ç”¨ç‡å’Œå“åº”æ—¶é—´
    """
    
    def calculate_task_priority(self, task: AITask, user_context: Dict) -> float:
        """è®¡ç®—ä»»åŠ¡ä¼˜å…ˆçº§"""
        # TODO: å®ç°æ™ºèƒ½ä¼˜å…ˆçº§è®¡ç®—
        pass
```

## âœ… å­¦ä¹ æ£€æŸ¥

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œè¯·ç¡®è®¤æ‚¨èƒ½å¤Ÿï¼š

- [ ] ç†è§£å¼‚æ­¥å¤„ç†åœ¨AIé›†æˆä¸­çš„é‡è¦æ€§
- [ ] è®¾è®¡é«˜æ•ˆçš„å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ç³»ç»Ÿ
- [ ] å®ç°å¹¶å‘AI APIè°ƒç”¨å’Œç»“æœå¤„ç†
- [ ] ç®¡ç†ä»»åŠ¡çŠ¶æ€å’Œé”™è¯¯å¤„ç†
- [ ] ä¼˜åŒ–å¼‚æ­¥å¤„ç†æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒ
- [ ] å®Œæˆå®è·µç»ƒä¹ 

## ğŸ“š ä¸‹ä¸€æ­¥

å¼‚æ­¥å¤„ç†æœºåˆ¶æŒæ¡åï¼Œè¯·ç»§ç»­å­¦ä¹ ï¼š
- [ç¬¬8ç« ï¼šç”¨æˆ·ç•Œé¢è®¾è®¡](../08-user-interface/tui-concepts.md)

---

**æ­å–œï¼æ‚¨å·²ç»å®Œæˆäº†AIé›†æˆåŠŸèƒ½çš„å­¦ä¹ ï¼** âš¡
