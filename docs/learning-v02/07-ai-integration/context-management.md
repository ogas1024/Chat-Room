# ä¸Šä¸‹æ–‡ç®¡ç†ç³»ç»Ÿ

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š
- ç†è§£AIå¯¹è¯ä¸­ä¸Šä¸‹æ–‡ç®¡ç†çš„é‡è¦æ€§å’ŒæŒ‘æˆ˜
- æŒæ¡å¯¹è¯å†å²çš„å­˜å‚¨ã€æ£€ç´¢å’Œä¼˜åŒ–æŠ€æœ¯
- å­¦ä¼šè®¾è®¡æ™ºèƒ½çš„ä¸Šä¸‹æ–‡å‹ç¼©å’Œç­›é€‰æœºåˆ¶
- åœ¨Chat-Roomé¡¹ç›®ä¸­å®ç°é«˜æ•ˆçš„ä¸Šä¸‹æ–‡ç®¡ç†ç³»ç»Ÿ

## ğŸ§  ä¸Šä¸‹æ–‡ç®¡ç†æ¶æ„

### ä¸Šä¸‹æ–‡ç®¡ç†ç³»ç»Ÿæ¦‚è§ˆ

```mermaid
graph TB
    subgraph "ä¸Šä¸‹æ–‡ç®¡ç†ç³»ç»Ÿ"
        A[å¯¹è¯è¾“å…¥<br/>Conversation Input] --> B[ä¸Šä¸‹æ–‡æå–<br/>Context Extraction]
        B --> C[å†å²æ£€ç´¢<br/>History Retrieval]
        C --> D[ç›¸å…³æ€§è¯„åˆ†<br/>Relevance Scoring]
        D --> E[ä¸Šä¸‹æ–‡å‹ç¼©<br/>Context Compression]
        E --> F[ä¸Šä¸‹æ–‡ç»„è£…<br/>Context Assembly]
        F --> G[AIæ¨¡å‹è¾“å…¥<br/>AI Model Input]
        
        H[å­˜å‚¨ç®¡ç†<br/>Storage Management] --> C
        I[ç¼“å­˜ç³»ç»Ÿ<br/>Cache System] --> C
        J[ç´¢å¼•æœåŠ¡<br/>Index Service] --> D
        K[å‹ç¼©ç®—æ³•<br/>Compression Algorithm] --> E
    end
    
    subgraph "ä¸Šä¸‹æ–‡ç±»å‹"
        L[å¯¹è¯å†å²<br/>Chat History]
        M[ç”¨æˆ·ç”»åƒ<br/>User Profile]
        N[ç¾¤ç»„ä¿¡æ¯<br/>Group Info]
        O[ç³»ç»ŸçŠ¶æ€<br/>System State]
    end
    
    B --> L
    B --> M
    B --> N
    B --> O
    
    style A fill:#e8f5e8
    style G fill:#f8d7da
```

### ä¸Šä¸‹æ–‡ç”Ÿå‘½å‘¨æœŸ

```mermaid
stateDiagram-v2
    [*] --> Collecting: å¼€å§‹æ”¶é›†
    Collecting --> Processing: å¤„ç†ä¸Šä¸‹æ–‡
    Processing --> Storing: å­˜å‚¨ä¸Šä¸‹æ–‡
    Storing --> Retrieving: æ£€ç´¢ä¸Šä¸‹æ–‡
    Retrieving --> Filtering: è¿‡æ»¤ç›¸å…³å†…å®¹
    Filtering --> Compressing: å‹ç¼©ä¸Šä¸‹æ–‡
    Compressing --> Assembling: ç»„è£…ä¸Šä¸‹æ–‡
    Assembling --> Using: ä½¿ç”¨ä¸Šä¸‹æ–‡
    Using --> Updating: æ›´æ–°ä¸Šä¸‹æ–‡
    Updating --> Storing: å­˜å‚¨æ›´æ–°
    Storing --> Archiving: å½’æ¡£å¤„ç†
    Archiving --> [*]: å®Œæˆå‘¨æœŸ
    
    Processing --> Error: å¤„ç†é”™è¯¯
    Error --> Collecting: é‡æ–°æ”¶é›†
```

## ğŸ’¾ ä¸Šä¸‹æ–‡ç®¡ç†å®ç°

### å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨

```python
# server/ai/context_manager.py - ä¸Šä¸‹æ–‡ç®¡ç†å™¨
import json
import time
import hashlib
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
import sqlite3
import threading
from collections import deque

@dataclass
class ConversationTurn:
    """å¯¹è¯è½®æ¬¡"""
    turn_id: str
    user_id: int
    username: str
    message: str
    ai_response: Optional[str] = None
    timestamp: float = None
    group_id: Optional[int] = None
    message_type: str = "text"
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = time.time()
        if self.metadata is None:
            self.metadata = {}
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'ConversationTurn':
        """ä»å­—å…¸åˆ›å»º"""
        return cls(**data)

@dataclass
class ContextWindow:
    """ä¸Šä¸‹æ–‡çª—å£"""
    window_id: str
    turns: List[ConversationTurn]
    max_turns: int = 10
    max_tokens: int = 2000
    created_at: float = None
    last_updated: float = None
    
    def __post_init__(self):
        if self.created_at is None:
            self.created_at = time.time()
        if self.last_updated is None:
            self.last_updated = time.time()
    
    def add_turn(self, turn: ConversationTurn):
        """æ·»åŠ å¯¹è¯è½®æ¬¡"""
        self.turns.append(turn)
        self.last_updated = time.time()
        
        # ä¿æŒçª—å£å¤§å°é™åˆ¶
        if len(self.turns) > self.max_turns:
            self.turns.pop(0)
    
    def get_recent_turns(self, count: int = None) -> List[ConversationTurn]:
        """è·å–æœ€è¿‘çš„å¯¹è¯è½®æ¬¡"""
        if count is None:
            count = self.max_turns
        return self.turns[-count:] if self.turns else []
    
    def estimate_tokens(self) -> int:
        """ä¼°ç®—tokenæ•°é‡"""
        total_chars = 0
        for turn in self.turns:
            total_chars += len(turn.message)
            if turn.ai_response:
                total_chars += len(turn.ai_response)
        
        # ç²—ç•¥ä¼°ç®—ï¼šä¸­æ–‡1å­—ç¬¦â‰ˆ1tokenï¼Œè‹±æ–‡4å­—ç¬¦â‰ˆ1token
        return int(total_chars * 0.8)

class ConversationContextManager:
    """
    å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    
    åŠŸèƒ½ï¼š
    1. ç®¡ç†å¤šç”¨æˆ·ã€å¤šç¾¤ç»„çš„å¯¹è¯ä¸Šä¸‹æ–‡
    2. æ™ºèƒ½å‹ç¼©å’Œç­›é€‰å†å²å¯¹è¯
    3. æä¾›ç›¸å…³æ€§è¯„åˆ†å’Œæ£€ç´¢
    4. ä¼˜åŒ–ä¸Šä¸‹æ–‡çª—å£å¤§å°
    """
    
    def __init__(self, db_path: str = "data/context.db", max_memory_windows: int = 100):
        self.db_path = db_path
        self.max_memory_windows = max_memory_windows
        
        # å†…å­˜ä¸­çš„ä¸Šä¸‹æ–‡çª—å£
        self.context_windows: Dict[str, ContextWindow] = {}
        self.window_access_times: Dict[str, float] = {}
        
        # çº¿ç¨‹å®‰å…¨é”
        self.lock = threading.RWLock()
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_database()
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # åˆ›å»ºå¯¹è¯å†å²è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS conversation_history (
                    turn_id TEXT PRIMARY KEY,
                    user_id INTEGER NOT NULL,
                    username TEXT NOT NULL,
                    message TEXT NOT NULL,
                    ai_response TEXT,
                    timestamp REAL NOT NULL,
                    group_id INTEGER,
                    message_type TEXT DEFAULT 'text',
                    metadata TEXT,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # åˆ›å»ºä¸Šä¸‹æ–‡æ‘˜è¦è¡¨
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS context_summaries (
                    summary_id TEXT PRIMARY KEY,
                    user_id INTEGER,
                    group_id INTEGER,
                    summary_content TEXT NOT NULL,
                    turn_count INTEGER NOT NULL,
                    start_time REAL NOT NULL,
                    end_time REAL NOT NULL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # åˆ›å»ºç´¢å¼•
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_history_user ON conversation_history(user_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_history_group ON conversation_history(group_id)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_history_timestamp ON conversation_history(timestamp)")
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
    
    def get_context_key(self, user_id: int, group_id: Optional[int] = None) -> str:
        """ç”Ÿæˆä¸Šä¸‹æ–‡é”®"""
        if group_id:
            return f"group_{group_id}_user_{user_id}"
        else:
            return f"user_{user_id}"
    
    def add_conversation_turn(self, user_id: int, username: str, message: str,
                            ai_response: str = None, group_id: int = None,
                            message_type: str = "text", metadata: Dict[str, Any] = None) -> str:
        """
        æ·»åŠ å¯¹è¯è½®æ¬¡
        
        Args:
            user_id: ç”¨æˆ·ID
            username: ç”¨æˆ·å
            message: ç”¨æˆ·æ¶ˆæ¯
            ai_response: AIå“åº”
            group_id: ç¾¤ç»„ID
            message_type: æ¶ˆæ¯ç±»å‹
            metadata: å…ƒæ•°æ®
            
        Returns:
            å¯¹è¯è½®æ¬¡ID
        """
        # ç”Ÿæˆè½®æ¬¡ID
        turn_id = self._generate_turn_id(user_id, message)
        
        # åˆ›å»ºå¯¹è¯è½®æ¬¡
        turn = ConversationTurn(
            turn_id=turn_id,
            user_id=user_id,
            username=username,
            message=message,
            ai_response=ai_response,
            group_id=group_id,
            message_type=message_type,
            metadata=metadata or {}
        )
        
        # è·å–ä¸Šä¸‹æ–‡é”®
        context_key = self.get_context_key(user_id, group_id)
        
        with self.lock.write_lock():
            # è·å–æˆ–åˆ›å»ºä¸Šä¸‹æ–‡çª—å£
            if context_key not in self.context_windows:
                self.context_windows[context_key] = ContextWindow(
                    window_id=context_key,
                    turns=[]
                )
            
            # æ·»åŠ åˆ°ä¸Šä¸‹æ–‡çª—å£
            self.context_windows[context_key].add_turn(turn)
            self.window_access_times[context_key] = time.time()
            
            # ç®¡ç†å†…å­˜ä½¿ç”¨
            self._manage_memory_usage()
        
        # å¼‚æ­¥ä¿å­˜åˆ°æ•°æ®åº“
        self._save_turn_to_database(turn)
        
        return turn_id
    
    def get_conversation_context(self, user_id: int, group_id: int = None,
                               max_turns: int = 10, max_tokens: int = 2000) -> List[ConversationTurn]:
        """
        è·å–å¯¹è¯ä¸Šä¸‹æ–‡
        
        Args:
            user_id: ç”¨æˆ·ID
            group_id: ç¾¤ç»„ID
            max_turns: æœ€å¤§è½®æ¬¡æ•°
            max_tokens: æœ€å¤§tokenæ•°
            
        Returns:
            å¯¹è¯è½®æ¬¡åˆ—è¡¨
        """
        context_key = self.get_context_key(user_id, group_id)
        
        with self.lock.read_lock():
            # ä»å†…å­˜è·å–
            if context_key in self.context_windows:
                window = self.context_windows[context_key]
                self.window_access_times[context_key] = time.time()
                
                # è·å–æœ€è¿‘çš„è½®æ¬¡
                recent_turns = window.get_recent_turns(max_turns)
                
                # æ ¹æ®tokené™åˆ¶è¿›ä¸€æ­¥ç­›é€‰
                return self._filter_by_tokens(recent_turns, max_tokens)
        
        # ä»æ•°æ®åº“åŠ è½½
        return self._load_context_from_database(user_id, group_id, max_turns, max_tokens)
    
    def get_relevant_context(self, user_id: int, current_message: str,
                           group_id: int = None, max_turns: int = 5) -> List[ConversationTurn]:
        """
        è·å–ç›¸å…³ä¸Šä¸‹æ–‡
        
        Args:
            user_id: ç”¨æˆ·ID
            current_message: å½“å‰æ¶ˆæ¯
            group_id: ç¾¤ç»„ID
            max_turns: æœ€å¤§è½®æ¬¡æ•°
            
        Returns:
            ç›¸å…³çš„å¯¹è¯è½®æ¬¡åˆ—è¡¨
        """
        # è·å–æ‰€æœ‰ä¸Šä¸‹æ–‡
        all_context = self.get_conversation_context(user_id, group_id, max_turns * 2)
        
        # è®¡ç®—ç›¸å…³æ€§è¯„åˆ†
        scored_turns = []
        for turn in all_context:
            score = self._calculate_relevance_score(current_message, turn)
            scored_turns.append((score, turn))
        
        # æŒ‰è¯„åˆ†æ’åºå¹¶è¿”å›å‰Nä¸ª
        scored_turns.sort(key=lambda x: x[0], reverse=True)
        return [turn for score, turn in scored_turns[:max_turns]]
    
    def compress_context(self, user_id: int, group_id: int = None) -> Optional[str]:
        """
        å‹ç¼©ä¸Šä¸‹æ–‡ä¸ºæ‘˜è¦
        
        Args:
            user_id: ç”¨æˆ·ID
            group_id: ç¾¤ç»„ID
            
        Returns:
            ä¸Šä¸‹æ–‡æ‘˜è¦
        """
        context_key = self.get_context_key(user_id, group_id)
        
        with self.lock.read_lock():
            if context_key not in self.context_windows:
                return None
            
            window = self.context_windows[context_key]
            if len(window.turns) < 5:  # å°‘äº5è½®å¯¹è¯ä¸å‹ç¼©
                return None
            
            # æå–å…³é”®ä¿¡æ¯
            summary_points = []
            topics = set()
            
            for turn in window.turns:
                # æå–å…³é”®è¯
                keywords = self._extract_keywords(turn.message)
                topics.update(keywords)
                
                # è®°å½•é‡è¦ä¿¡æ¯
                if any(keyword in turn.message.lower() for keyword in ['é—®é¢˜', 'å¸®åŠ©', 'è§£å†³', 'å»ºè®®']):
                    summary_points.append(f"ç”¨æˆ·è¯¢é—®: {turn.message[:50]}...")
                
                if turn.ai_response and len(turn.ai_response) > 100:
                    summary_points.append(f"AIå›å¤è¦ç‚¹: {turn.ai_response[:50]}...")
            
            # ç”Ÿæˆæ‘˜è¦
            summary = f"å¯¹è¯ä¸»é¢˜: {', '.join(list(topics)[:5])}\n"
            summary += f"å…³é”®äº¤äº’: {'; '.join(summary_points[:3])}\n"
            summary += f"å¯¹è¯è½®æ¬¡: {len(window.turns)}"
            
            return summary
    
    def clear_old_context(self, days_old: int = 7):
        """æ¸…ç†æ—§çš„ä¸Šä¸‹æ–‡æ•°æ®"""
        cutoff_time = time.time() - (days_old * 24 * 3600)
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # åˆ é™¤æ—§çš„å¯¹è¯è®°å½•
            cursor.execute("""
                DELETE FROM conversation_history 
                WHERE timestamp < ?
            """, (cutoff_time,))
            
            # åˆ é™¤æ—§çš„æ‘˜è¦
            cursor.execute("""
                DELETE FROM context_summaries 
                WHERE end_time < ?
            """, (cutoff_time,))
            
            deleted_count = cursor.rowcount
            conn.commit()
            conn.close()
            
            print(f"æ¸…ç†äº† {deleted_count} æ¡æ—§çš„ä¸Šä¸‹æ–‡è®°å½•")
            
        except Exception as e:
            print(f"æ¸…ç†ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
    
    def _generate_turn_id(self, user_id: int, message: str) -> str:
        """ç”Ÿæˆè½®æ¬¡ID"""
        content = f"{user_id}_{message}_{time.time()}"
        return hashlib.md5(content.encode()).hexdigest()[:16]
    
    def _filter_by_tokens(self, turns: List[ConversationTurn], max_tokens: int) -> List[ConversationTurn]:
        """æ ¹æ®tokené™åˆ¶ç­›é€‰è½®æ¬¡"""
        filtered_turns = []
        current_tokens = 0
        
        # ä»æœ€æ–°çš„å¼€å§‹æ·»åŠ 
        for turn in reversed(turns):
            turn_tokens = len(turn.message) + (len(turn.ai_response) if turn.ai_response else 0)
            turn_tokens = int(turn_tokens * 0.8)  # ä¼°ç®—tokenæ•°
            
            if current_tokens + turn_tokens <= max_tokens:
                filtered_turns.insert(0, turn)
                current_tokens += turn_tokens
            else:
                break
        
        return filtered_turns
    
    def _calculate_relevance_score(self, current_message: str, turn: ConversationTurn) -> float:
        """è®¡ç®—ç›¸å…³æ€§è¯„åˆ†"""
        score = 0.0
        
        # æ—¶é—´è¡°å‡
        time_diff = time.time() - turn.timestamp
        time_score = max(0, 1 - time_diff / (24 * 3600))  # 24å°æ—¶å†…çš„å¯¹è¯æ›´ç›¸å…³
        score += time_score * 0.3
        
        # å…³é”®è¯åŒ¹é…
        current_keywords = set(self._extract_keywords(current_message))
        turn_keywords = set(self._extract_keywords(turn.message))
        
        if current_keywords and turn_keywords:
            keyword_overlap = len(current_keywords & turn_keywords) / len(current_keywords | turn_keywords)
            score += keyword_overlap * 0.5
        
        # æ¶ˆæ¯ç±»å‹åŒ¹é…
        if turn.message_type == "text":
            score += 0.2
        
        return score
    
    def _extract_keywords(self, text: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„NLPæŠ€æœ¯ï¼‰
        import re
        
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·å¹¶åˆ†è¯
        words = re.findall(r'\b\w+\b', text.lower())
        
        # è¿‡æ»¤åœç”¨è¯
        stop_words = {'çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'ä½ ', 'ä»–', 'å¥¹', 'å®ƒ', 'æˆ‘ä»¬', 'ä½ ä»¬', 'ä»–ä»¬',
                     'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for'}
        
        keywords = [word for word in words if word not in stop_words and len(word) > 1]
        
        return keywords[:10]  # è¿”å›å‰10ä¸ªå…³é”®è¯
    
    def _manage_memory_usage(self):
        """ç®¡ç†å†…å­˜ä½¿ç”¨"""
        if len(self.context_windows) <= self.max_memory_windows:
            return
        
        # æŒ‰è®¿é—®æ—¶é—´æ’åºï¼Œç§»é™¤æœ€ä¹…æœªè®¿é—®çš„çª—å£
        sorted_windows = sorted(
            self.window_access_times.items(),
            key=lambda x: x[1]
        )
        
        # ç§»é™¤æœ€æ—§çš„çª—å£
        windows_to_remove = len(self.context_windows) - self.max_memory_windows
        for i in range(windows_to_remove):
            window_key = sorted_windows[i][0]
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            if window_key in self.context_windows:
                self._save_window_to_database(self.context_windows[window_key])
                del self.context_windows[window_key]
                del self.window_access_times[window_key]
    
    def _save_turn_to_database(self, turn: ConversationTurn):
        """ä¿å­˜è½®æ¬¡åˆ°æ•°æ®åº“"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute("""
                INSERT OR REPLACE INTO conversation_history 
                (turn_id, user_id, username, message, ai_response, timestamp, 
                 group_id, message_type, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                turn.turn_id, turn.user_id, turn.username, turn.message,
                turn.ai_response, turn.timestamp, turn.group_id,
                turn.message_type, json.dumps(turn.metadata)
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            print(f"ä¿å­˜å¯¹è¯è½®æ¬¡å¤±è´¥: {e}")
    
    def _save_window_to_database(self, window: ContextWindow):
        """ä¿å­˜çª—å£åˆ°æ•°æ®åº“"""
        for turn in window.turns:
            self._save_turn_to_database(turn)
    
    def _load_context_from_database(self, user_id: int, group_id: int = None,
                                  max_turns: int = 10, max_tokens: int = 2000) -> List[ConversationTurn]:
        """ä»æ•°æ®åº“åŠ è½½ä¸Šä¸‹æ–‡"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()
            
            if group_id:
                cursor.execute("""
                    SELECT * FROM conversation_history 
                    WHERE user_id = ? AND group_id = ?
                    ORDER BY timestamp DESC 
                    LIMIT ?
                """, (user_id, group_id, max_turns))
            else:
                cursor.execute("""
                    SELECT * FROM conversation_history 
                    WHERE user_id = ? AND group_id IS NULL
                    ORDER BY timestamp DESC 
                    LIMIT ?
                """, (user_id, max_turns))
            
            rows = cursor.fetchall()
            conn.close()
            
            turns = []
            for row in rows:
                metadata = json.loads(row['metadata']) if row['metadata'] else {}
                
                turn = ConversationTurn(
                    turn_id=row['turn_id'],
                    user_id=row['user_id'],
                    username=row['username'],
                    message=row['message'],
                    ai_response=row['ai_response'],
                    timestamp=row['timestamp'],
                    group_id=row['group_id'],
                    message_type=row['message_type'],
                    metadata=metadata
                )
                turns.append(turn)
            
            # æŒ‰æ—¶é—´æ­£åºè¿”å›
            return list(reversed(turns))
            
        except Exception as e:
            print(f"ä»æ•°æ®åº“åŠ è½½ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return []

# ä½¿ç”¨ç¤ºä¾‹
def demo_context_management():
    """ä¸Šä¸‹æ–‡ç®¡ç†æ¼”ç¤º"""
    manager = ConversationContextManager()
    
    print("=== ä¸Šä¸‹æ–‡ç®¡ç†æ¼”ç¤º ===")
    
    # æ·»åŠ å¯¹è¯è½®æ¬¡
    turn1_id = manager.add_conversation_turn(
        user_id=1,
        username="alice",
        message="ä½ å¥½ï¼Œæˆ‘æƒ³å­¦ä¹ Pythonç¼–ç¨‹",
        ai_response="ä½ å¥½ï¼Pythonæ˜¯ä¸€é—¨å¾ˆæ£’çš„ç¼–ç¨‹è¯­è¨€ã€‚ä½ æƒ³ä»å“ªä¸ªæ–¹é¢å¼€å§‹å­¦ä¹ å‘¢ï¼Ÿ",
        group_id=1
    )
    
    turn2_id = manager.add_conversation_turn(
        user_id=1,
        username="alice",
        message="æˆ‘æƒ³å­¦ä¹ æ•°æ®åˆ†æ",
        ai_response="æ•°æ®åˆ†ææ˜¯Pythonçš„å¼ºé¡¹ï¼å»ºè®®ä½ ä»pandaså’Œnumpyå¼€å§‹å­¦ä¹ ã€‚",
        group_id=1
    )
    
    # è·å–ä¸Šä¸‹æ–‡
    context = manager.get_conversation_context(user_id=1, group_id=1)
    print(f"è·å–åˆ° {len(context)} è½®å¯¹è¯")
    
    for turn in context:
        print(f"ç”¨æˆ·: {turn.message}")
        print(f"AI: {turn.ai_response}")
        print("-" * 50)
    
    # è·å–ç›¸å…³ä¸Šä¸‹æ–‡
    relevant_context = manager.get_relevant_context(
        user_id=1,
        current_message="pandasæ€ä¹ˆä½¿ç”¨ï¼Ÿ",
        group_id=1
    )
    
    print(f"ç›¸å…³ä¸Šä¸‹æ–‡: {len(relevant_context)} è½®")
    
    # å‹ç¼©ä¸Šä¸‹æ–‡
    summary = manager.compress_context(user_id=1, group_id=1)
    if summary:
        print(f"ä¸Šä¸‹æ–‡æ‘˜è¦:\n{summary}")

if __name__ == "__main__":
    demo_context_management()
```

## ğŸ¯ å®è·µç»ƒä¹ 

### ç»ƒä¹ 1ï¼šæ™ºèƒ½ä¸Šä¸‹æ–‡å‹ç¼©
```python
class IntelligentContextCompressor:
    """
    æ™ºèƒ½ä¸Šä¸‹æ–‡å‹ç¼©ç»ƒä¹ 
    
    è¦æ±‚ï¼š
    1. å®ç°åŸºäºé‡è¦æ€§çš„ä¸Šä¸‹æ–‡ç­›é€‰
    2. ä½¿ç”¨AIæ¨¡å‹ç”Ÿæˆä¸Šä¸‹æ–‡æ‘˜è¦
    3. æ”¯æŒå¤šå±‚æ¬¡çš„ä¸Šä¸‹æ–‡å‹ç¼©
    4. ä¿æŒå…³é”®ä¿¡æ¯çš„å®Œæ•´æ€§
    """
    
    def compress_with_ai(self, conversation_turns: List[ConversationTurn]) -> str:
        """ä½¿ç”¨AIå‹ç¼©ä¸Šä¸‹æ–‡"""
        # TODO: å®ç°AIé©±åŠ¨çš„ä¸Šä¸‹æ–‡å‹ç¼©
        pass
```

### ç»ƒä¹ 2ï¼šè·¨ä¼šè¯ä¸Šä¸‹æ–‡å…³è”
```python
class CrossSessionContextLinker:
    """
    è·¨ä¼šè¯ä¸Šä¸‹æ–‡å…³è”ç»ƒä¹ 
    
    è¦æ±‚ï¼š
    1. è¯†åˆ«ä¸åŒä¼šè¯é—´çš„å…³è”æ€§
    2. å»ºç«‹ç”¨æˆ·å…´è¶£å’Œåå¥½æ¨¡å‹
    3. å®ç°é•¿æœŸè®°å¿†æœºåˆ¶
    4. æ”¯æŒä¸Šä¸‹æ–‡çš„è¯­ä¹‰æ£€ç´¢
    """
    
    def link_related_sessions(self, user_id: int, current_topic: str) -> List[str]:
        """å…³è”ç›¸å…³ä¼šè¯"""
        # TODO: å®ç°è·¨ä¼šè¯å…³è”
        pass
```

## âœ… å­¦ä¹ æ£€æŸ¥

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œè¯·ç¡®è®¤æ‚¨èƒ½å¤Ÿï¼š

- [ ] ç†è§£ä¸Šä¸‹æ–‡ç®¡ç†çš„é‡è¦æ€§å’ŒæŒ‘æˆ˜
- [ ] è®¾è®¡é«˜æ•ˆçš„ä¸Šä¸‹æ–‡å­˜å‚¨å’Œæ£€ç´¢ç³»ç»Ÿ
- [ ] å®ç°æ™ºèƒ½çš„ä¸Šä¸‹æ–‡å‹ç¼©å’Œç­›é€‰
- [ ] ç®¡ç†å¤šç”¨æˆ·ã€å¤šç¾¤ç»„çš„ä¸Šä¸‹æ–‡
- [ ] ä¼˜åŒ–ä¸Šä¸‹æ–‡çª—å£å¤§å°å’Œæ€§èƒ½
- [ ] å®Œæˆå®è·µç»ƒä¹ 

## ğŸ“š ä¸‹ä¸€æ­¥

ä¸Šä¸‹æ–‡ç®¡ç†ç³»ç»ŸæŒæ¡åï¼Œè¯·ç»§ç»­å­¦ä¹ ï¼š
- [å¼‚æ­¥å¤„ç†](async-processing.md)

---

**ç°åœ¨æ‚¨å·²ç»æŒæ¡äº†æ™ºèƒ½ä¸Šä¸‹æ–‡ç®¡ç†æŠ€æœ¯ï¼** ğŸ§ 
