# æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

## ğŸ¯ å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬ç« å­¦ä¹ ï¼Œæ‚¨å°†èƒ½å¤Ÿï¼š
- ç†è§£ç°ä»£åº”ç”¨æ€§èƒ½ä¼˜åŒ–çš„æ ¸å¿ƒç†å¿µå’Œæ–¹æ³•è®º
- æŒæ¡Pythonå¼‚æ­¥ç¼–ç¨‹å’Œå¹¶å‘ä¼˜åŒ–æŠ€æœ¯
- å­¦ä¼šä¸ºChat-Roomé¡¹ç›®è®¾è®¡é«˜æ€§èƒ½æ¶æ„
- å®ç°ç³»ç»Ÿæ€§èƒ½ç›‘æ§å’Œè°ƒä¼˜æœºåˆ¶

## âš¡ æ€§èƒ½ä¼˜åŒ–ä½“ç³»

### æ€§èƒ½ä¼˜åŒ–å±‚æ¬¡

```mermaid
graph TB
    subgraph "æ€§èƒ½ä¼˜åŒ–å±‚æ¬¡"
        A[ç®—æ³•ä¼˜åŒ–<br/>Algorithm Optimization] --> A1[æ—¶é—´å¤æ‚åº¦<br/>Time Complexity]
        A --> A2[ç©ºé—´å¤æ‚åº¦<br/>Space Complexity]
        A --> A3[æ•°æ®ç»“æ„é€‰æ‹©<br/>Data Structure Selection]
        
        B[ä»£ç ä¼˜åŒ–<br/>Code Optimization] --> B1[å¾ªç¯ä¼˜åŒ–<br/>Loop Optimization]
        B --> B2[å‡½æ•°è°ƒç”¨ä¼˜åŒ–<br/>Function Call Optimization]
        B --> B3[å†…å­˜ç®¡ç†<br/>Memory Management]
        
        C[å¹¶å‘ä¼˜åŒ–<br/>Concurrency Optimization] --> C1[å¼‚æ­¥ç¼–ç¨‹<br/>Async Programming]
        C --> C2[å¤šçº¿ç¨‹<br/>Multi-threading]
        C --> C3[å¤šè¿›ç¨‹<br/>Multi-processing]
        
        D[ç³»ç»Ÿä¼˜åŒ–<br/>System Optimization] --> D1[I/Oä¼˜åŒ–<br/>I/O Optimization]
        D --> D2[ç½‘ç»œä¼˜åŒ–<br/>Network Optimization]
        D --> D3[æ•°æ®åº“ä¼˜åŒ–<br/>Database Optimization]
    end
    
    A --> B
    B --> C
    C --> D
    
    style A fill:#e8f5e8
    style D fill:#f8d7da
```

### æ€§èƒ½ç›‘æ§æŒ‡æ ‡

```mermaid
graph LR
    subgraph "æ€§èƒ½ç›‘æ§æŒ‡æ ‡"
        A[å“åº”æ—¶é—´<br/>Response Time] --> A1[å¹³å‡å“åº”æ—¶é—´<br/>Average Response Time]
        A --> A2[95%åˆ†ä½æ•°<br/>95th Percentile]
        A --> A3[99%åˆ†ä½æ•°<br/>99th Percentile]
        
        B[ååé‡<br/>Throughput] --> B1[æ¯ç§’è¯·æ±‚æ•°<br/>Requests Per Second]
        B --> B2[æ¯ç§’äº‹åŠ¡æ•°<br/>Transactions Per Second]
        B --> B3[å¹¶å‘ç”¨æˆ·æ•°<br/>Concurrent Users]
        
        C[èµ„æºä½¿ç”¨<br/>Resource Usage] --> C1[CPUä½¿ç”¨ç‡<br/>CPU Usage]
        C --> C2[å†…å­˜ä½¿ç”¨ç‡<br/>Memory Usage]
        C --> C3[ç½‘ç»œå¸¦å®½<br/>Network Bandwidth]
        
        D[é”™è¯¯ç‡<br/>Error Rate] --> D1[HTTPé”™è¯¯ç‡<br/>HTTP Error Rate]
        D --> D2[è¶…æ—¶ç‡<br/>Timeout Rate]
        D --> D3[è¿æ¥å¤±è´¥ç‡<br/>Connection Failure Rate]
    end
    
    style A fill:#e8f5e8
    style B fill:#fff3cd
    style C fill:#f8d7da
    style D fill:#d1ecf1
```

## ğŸ”§ æ€§èƒ½ä¼˜åŒ–å®ç°

### Chat-Roomæ€§èƒ½ä¼˜åŒ–ç³»ç»Ÿ

```python
# server/optimization/performance_optimizer.py - æ€§èƒ½ä¼˜åŒ–å™¨
import asyncio
import time
import threading
import multiprocessing
from typing import Dict, List, Any, Callable, Optional, Union
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from functools import wraps, lru_cache
import weakref
import gc
from collections import deque, defaultdict
import psutil
import cProfile
import pstats
import io

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡"""
    response_time: float
    throughput: float
    cpu_usage: float
    memory_usage: float
    concurrent_connections: int
    error_rate: float
    timestamp: float = field(default_factory=time.time)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "response_time": self.response_time,
            "throughput": self.throughput,
            "cpu_usage": self.cpu_usage,
            "memory_usage": self.memory_usage,
            "concurrent_connections": self.concurrent_connections,
            "error_rate": self.error_rate,
            "timestamp": self.timestamp
        }

class AsyncOptimizer:
    """
    å¼‚æ­¥ä¼˜åŒ–å™¨
    
    åŠŸèƒ½ï¼š
    1. å¼‚æ­¥ä»»åŠ¡è°ƒåº¦ä¼˜åŒ–
    2. åç¨‹æ± ç®¡ç†
    3. äº‹ä»¶å¾ªç¯ä¼˜åŒ–
    4. å¼‚æ­¥I/Oä¼˜åŒ–
    """
    
    def __init__(self, max_workers: int = 100):
        self.max_workers = max_workers
        self.semaphore = asyncio.Semaphore(max_workers)
        self.task_queue = asyncio.Queue()
        self.active_tasks = set()
        self.metrics = deque(maxlen=1000)
    
    async def execute_with_limit(self, coro):
        """é™åˆ¶å¹¶å‘æ‰§è¡Œåç¨‹"""
        async with self.semaphore:
            start_time = time.time()
            try:
                result = await coro
                execution_time = time.time() - start_time
                self._record_metric("success", execution_time)
                return result
            except Exception as e:
                execution_time = time.time() - start_time
                self._record_metric("error", execution_time)
                raise
    
    def _record_metric(self, status: str, execution_time: float):
        """è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        self.metrics.append({
            "status": status,
            "execution_time": execution_time,
            "timestamp": time.time(),
            "active_tasks": len(self.active_tasks)
        })
    
    async def batch_execute(self, coros: List[Callable], batch_size: int = 10):
        """æ‰¹é‡æ‰§è¡Œåç¨‹"""
        results = []
        
        for i in range(0, len(coros), batch_size):
            batch = coros[i:i + batch_size]
            batch_results = await asyncio.gather(
                *[self.execute_with_limit(coro()) for coro in batch],
                return_exceptions=True
            )
            results.extend(batch_results)
        
        return results
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        if not self.metrics:
            return {}
        
        recent_metrics = list(self.metrics)[-100:]  # æœ€è¿‘100ä¸ªæŒ‡æ ‡
        
        execution_times = [m["execution_time"] for m in recent_metrics]
        success_count = sum(1 for m in recent_metrics if m["status"] == "success")
        error_count = len(recent_metrics) - success_count
        
        return {
            "avg_execution_time": sum(execution_times) / len(execution_times),
            "max_execution_time": max(execution_times),
            "min_execution_time": min(execution_times),
            "success_rate": success_count / len(recent_metrics) * 100,
            "error_rate": error_count / len(recent_metrics) * 100,
            "active_tasks": len(self.active_tasks)
        }

class CacheOptimizer:
    """
    ç¼“å­˜ä¼˜åŒ–å™¨
    
    åŠŸèƒ½ï¼š
    1. å¤šçº§ç¼“å­˜ç®¡ç†
    2. ç¼“å­˜ç­–ç•¥ä¼˜åŒ–
    3. ç¼“å­˜å‘½ä¸­ç‡ç›‘æ§
    4. è‡ªåŠ¨ç¼“å­˜æ¸…ç†
    """
    
    def __init__(self):
        self.l1_cache = {}  # å†…å­˜ç¼“å­˜
        self.l2_cache = {}  # æŒä¹…åŒ–ç¼“å­˜
        self.cache_stats = defaultdict(int)
        self.cache_ttl = {}  # ç¼“å­˜è¿‡æœŸæ—¶é—´
        self.max_cache_size = 1000
    
    def get(self, key: str, default=None) -> Any:
        """è·å–ç¼“å­˜å€¼"""
        # æ£€æŸ¥L1ç¼“å­˜
        if key in self.l1_cache:
            if self._is_cache_valid(key):
                self.cache_stats["l1_hits"] += 1
                return self.l1_cache[key]
            else:
                self._remove_expired_cache(key)
        
        # æ£€æŸ¥L2ç¼“å­˜
        if key in self.l2_cache:
            if self._is_cache_valid(key):
                self.cache_stats["l2_hits"] += 1
                # æå‡åˆ°L1ç¼“å­˜
                self.l1_cache[key] = self.l2_cache[key]
                return self.l2_cache[key]
            else:
                self._remove_expired_cache(key)
        
        self.cache_stats["misses"] += 1
        return default
    
    def set(self, key: str, value: Any, ttl: int = 3600):
        """è®¾ç½®ç¼“å­˜å€¼"""
        current_time = time.time()
        
        # æ£€æŸ¥ç¼“å­˜å¤§å°é™åˆ¶
        if len(self.l1_cache) >= self.max_cache_size:
            self._evict_lru_cache()
        
        self.l1_cache[key] = value
        self.cache_ttl[key] = current_time + ttl
        self.cache_stats["sets"] += 1
    
    def _is_cache_valid(self, key: str) -> bool:
        """æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ"""
        if key not in self.cache_ttl:
            return True
        
        return time.time() < self.cache_ttl[key]
    
    def _remove_expired_cache(self, key: str):
        """ç§»é™¤è¿‡æœŸç¼“å­˜"""
        self.l1_cache.pop(key, None)
        self.l2_cache.pop(key, None)
        self.cache_ttl.pop(key, None)
    
    def _evict_lru_cache(self):
        """LRUç¼“å­˜æ·˜æ±°"""
        # ç®€å•å®ç°ï¼šç§»é™¤æœ€æ—§çš„ç¼“å­˜é¡¹
        if self.l1_cache:
            oldest_key = next(iter(self.l1_cache))
            self.l2_cache[oldest_key] = self.l1_cache.pop(oldest_key)
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        total_requests = (self.cache_stats["l1_hits"] + 
                         self.cache_stats["l2_hits"] + 
                         self.cache_stats["misses"])
        
        if total_requests == 0:
            return {"hit_rate": 0, "miss_rate": 0}
        
        hit_rate = ((self.cache_stats["l1_hits"] + self.cache_stats["l2_hits"]) / 
                   total_requests * 100)
        
        return {
            "l1_hits": self.cache_stats["l1_hits"],
            "l2_hits": self.cache_stats["l2_hits"],
            "misses": self.cache_stats["misses"],
            "sets": self.cache_stats["sets"],
            "hit_rate": hit_rate,
            "miss_rate": 100 - hit_rate,
            "cache_size": len(self.l1_cache) + len(self.l2_cache)
        }

class ConnectionPoolOptimizer:
    """
    è¿æ¥æ± ä¼˜åŒ–å™¨
    
    åŠŸèƒ½ï¼š
    1. è¿æ¥æ± å¤§å°åŠ¨æ€è°ƒæ•´
    2. è¿æ¥å¥åº·æ£€æŸ¥
    3. è¿æ¥å¤ç”¨ä¼˜åŒ–
    4. è¿æ¥è¶…æ—¶ç®¡ç†
    """
    
    def __init__(self, min_connections: int = 5, max_connections: int = 100):
        self.min_connections = min_connections
        self.max_connections = max_connections
        self.active_connections = set()
        self.idle_connections = deque()
        self.connection_stats = defaultdict(int)
        self.lock = asyncio.Lock()
    
    async def get_connection(self):
        """è·å–è¿æ¥"""
        async with self.lock:
            # å°è¯•ä»ç©ºé—²è¿æ¥æ± è·å–
            while self.idle_connections:
                conn = self.idle_connections.popleft()
                if await self._is_connection_healthy(conn):
                    self.active_connections.add(conn)
                    self.connection_stats["reused"] += 1
                    return conn
                else:
                    await self._close_connection(conn)
            
            # åˆ›å»ºæ–°è¿æ¥
            if len(self.active_connections) < self.max_connections:
                conn = await self._create_connection()
                self.active_connections.add(conn)
                self.connection_stats["created"] += 1
                return conn
            
            # è¿æ¥æ± å·²æ»¡ï¼Œç­‰å¾…
            raise Exception("è¿æ¥æ± å·²æ»¡")
    
    async def return_connection(self, conn):
        """å½’è¿˜è¿æ¥"""
        async with self.lock:
            if conn in self.active_connections:
                self.active_connections.remove(conn)
                
                if await self._is_connection_healthy(conn):
                    self.idle_connections.append(conn)
                    self.connection_stats["returned"] += 1
                else:
                    await self._close_connection(conn)
                    self.connection_stats["closed"] += 1
    
    async def _create_connection(self):
        """åˆ›å»ºæ–°è¿æ¥"""
        # æ¨¡æ‹Ÿè¿æ¥åˆ›å»º
        class MockConnection:
            def __init__(self):
                self.created_at = time.time()
                self.healthy = True
            
            async def close(self):
                self.healthy = False
        
        return MockConnection()
    
    async def _is_connection_healthy(self, conn) -> bool:
        """æ£€æŸ¥è¿æ¥å¥åº·çŠ¶æ€"""
        # æ¨¡æ‹Ÿå¥åº·æ£€æŸ¥
        return hasattr(conn, 'healthy') and conn.healthy
    
    async def _close_connection(self, conn):
        """å…³é—­è¿æ¥"""
        if hasattr(conn, 'close'):
            await conn.close()
    
    def get_pool_stats(self) -> Dict[str, Any]:
        """è·å–è¿æ¥æ± ç»Ÿè®¡"""
        return {
            "active_connections": len(self.active_connections),
            "idle_connections": len(self.idle_connections),
            "total_connections": len(self.active_connections) + len(self.idle_connections),
            "max_connections": self.max_connections,
            "connection_stats": dict(self.connection_stats)
        }

class PerformanceProfiler:
    """
    æ€§èƒ½åˆ†æå™¨
    
    åŠŸèƒ½ï¼š
    1. ä»£ç æ€§èƒ½åˆ†æ
    2. çƒ­ç‚¹å‡½æ•°è¯†åˆ«
    3. å†…å­˜ä½¿ç”¨åˆ†æ
    4. æ€§èƒ½æŠ¥å‘Šç”Ÿæˆ
    """
    
    def __init__(self):
        self.profiler = None
        self.profile_data = {}
        self.memory_snapshots = []
    
    def start_profiling(self):
        """å¼€å§‹æ€§èƒ½åˆ†æ"""
        self.profiler = cProfile.Profile()
        self.profiler.enable()
    
    def stop_profiling(self):
        """åœæ­¢æ€§èƒ½åˆ†æ"""
        if self.profiler:
            self.profiler.disable()
    
    def get_profile_stats(self, sort_by: str = 'cumulative') -> str:
        """è·å–æ€§èƒ½åˆ†æç»Ÿè®¡"""
        if not self.profiler:
            return "æ²¡æœ‰æ€§èƒ½åˆ†ææ•°æ®"
        
        s = io.StringIO()
        stats = pstats.Stats(self.profiler, stream=s)
        stats.sort_stats(sort_by)
        stats.print_stats(20)  # æ˜¾ç¤ºå‰20ä¸ªå‡½æ•°
        
        return s.getvalue()
    
    def profile_function(self, func):
        """å‡½æ•°æ€§èƒ½åˆ†æè£…é¥°å™¨"""
        @wraps(func)
        def wrapper(*args, **kwargs):
            start_time = time.time()
            start_memory = psutil.Process().memory_info().rss
            
            try:
                result = func(*args, **kwargs)
                return result
            finally:
                end_time = time.time()
                end_memory = psutil.Process().memory_info().rss
                
                func_name = f"{func.__module__}.{func.__name__}"
                self.profile_data[func_name] = {
                    "execution_time": end_time - start_time,
                    "memory_delta": end_memory - start_memory,
                    "call_count": self.profile_data.get(func_name, {}).get("call_count", 0) + 1
                }
        
        return wrapper
    
    def take_memory_snapshot(self, label: str = ""):
        """è·å–å†…å­˜å¿«ç…§"""
        process = psutil.Process()
        memory_info = process.memory_info()
        
        snapshot = {
            "label": label,
            "timestamp": time.time(),
            "rss": memory_info.rss,  # ç‰©ç†å†…å­˜
            "vms": memory_info.vms,  # è™šæ‹Ÿå†…å­˜
            "percent": process.memory_percent(),
            "available": psutil.virtual_memory().available
        }
        
        self.memory_snapshots.append(snapshot)
        return snapshot
    
    def analyze_memory_usage(self) -> Dict[str, Any]:
        """åˆ†æå†…å­˜ä½¿ç”¨æƒ…å†µ"""
        if len(self.memory_snapshots) < 2:
            return {"error": "éœ€è¦è‡³å°‘2ä¸ªå†…å­˜å¿«ç…§"}
        
        first_snapshot = self.memory_snapshots[0]
        last_snapshot = self.memory_snapshots[-1]
        
        memory_growth = last_snapshot["rss"] - first_snapshot["rss"]
        time_elapsed = last_snapshot["timestamp"] - first_snapshot["timestamp"]
        
        return {
            "memory_growth": memory_growth,
            "memory_growth_mb": memory_growth / 1024 / 1024,
            "time_elapsed": time_elapsed,
            "growth_rate": memory_growth / time_elapsed if time_elapsed > 0 else 0,
            "current_usage": last_snapshot["rss"] / 1024 / 1024,
            "usage_percent": last_snapshot["percent"]
        }

class PerformanceOptimizer:
    """
    æ€§èƒ½ä¼˜åŒ–å™¨ä¸»ç±»
    
    åŠŸèƒ½ï¼š
    1. é›†æˆå„ç§ä¼˜åŒ–å™¨
    2. æ€§èƒ½ç›‘æ§å’Œåˆ†æ
    3. è‡ªåŠ¨ä¼˜åŒ–å»ºè®®
    4. æ€§èƒ½æŠ¥å‘Šç”Ÿæˆ
    """
    
    def __init__(self):
        self.async_optimizer = AsyncOptimizer()
        self.cache_optimizer = CacheOptimizer()
        self.connection_pool = ConnectionPoolOptimizer()
        self.profiler = PerformanceProfiler()
        self.metrics_history = deque(maxlen=1000)
    
    def collect_metrics(self) -> PerformanceMetrics:
        """æ”¶é›†æ€§èƒ½æŒ‡æ ‡"""
        # è·å–ç³»ç»ŸæŒ‡æ ‡
        cpu_usage = psutil.cpu_percent()
        memory_usage = psutil.virtual_memory().percent
        
        # è·å–åº”ç”¨æŒ‡æ ‡
        async_stats = self.async_optimizer.get_performance_stats()
        cache_stats = self.cache_optimizer.get_cache_stats()
        pool_stats = self.connection_pool.get_pool_stats()
        
        metrics = PerformanceMetrics(
            response_time=async_stats.get("avg_execution_time", 0),
            throughput=1.0 / async_stats.get("avg_execution_time", 1),
            cpu_usage=cpu_usage,
            memory_usage=memory_usage,
            concurrent_connections=pool_stats["active_connections"],
            error_rate=async_stats.get("error_rate", 0)
        )
        
        self.metrics_history.append(metrics)
        return metrics
    
    def generate_optimization_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        if not self.metrics_history:
            return {"error": "æ²¡æœ‰æ€§èƒ½æ•°æ®"}
        
        recent_metrics = list(self.metrics_history)[-100:]
        
        # è®¡ç®—å¹³å‡å€¼
        avg_response_time = sum(m.response_time for m in recent_metrics) / len(recent_metrics)
        avg_cpu_usage = sum(m.cpu_usage for m in recent_metrics) / len(recent_metrics)
        avg_memory_usage = sum(m.memory_usage for m in recent_metrics) / len(recent_metrics)
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        recommendations = []
        
        if avg_response_time > 1.0:
            recommendations.append("å“åº”æ—¶é—´è¿‡é•¿ï¼Œå»ºè®®ä¼˜åŒ–å¼‚æ­¥å¤„ç†é€»è¾‘")
        
        if avg_cpu_usage > 80:
            recommendations.append("CPUä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®ä¼˜åŒ–è®¡ç®—å¯†é›†å‹æ“ä½œ")
        
        if avg_memory_usage > 85:
            recommendations.append("å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ï¼Œå»ºè®®æ£€æŸ¥å†…å­˜æ³„æ¼")
        
        cache_stats = self.cache_optimizer.get_cache_stats()
        if cache_stats.get("hit_rate", 0) < 70:
            recommendations.append("ç¼“å­˜å‘½ä¸­ç‡åä½ï¼Œå»ºè®®ä¼˜åŒ–ç¼“å­˜ç­–ç•¥")
        
        return {
            "performance_summary": {
                "avg_response_time": avg_response_time,
                "avg_cpu_usage": avg_cpu_usage,
                "avg_memory_usage": avg_memory_usage,
                "cache_hit_rate": cache_stats.get("hit_rate", 0)
            },
            "optimization_recommendations": recommendations,
            "detailed_stats": {
                "async_stats": self.async_optimizer.get_performance_stats(),
                "cache_stats": cache_stats,
                "pool_stats": self.connection_pool.get_pool_stats()
            }
        }

# ä½¿ç”¨ç¤ºä¾‹
async def demo_performance_optimization():
    """æ€§èƒ½ä¼˜åŒ–æ¼”ç¤º"""
    print("=== Chat-Roomæ€§èƒ½ä¼˜åŒ–æ¼”ç¤º ===")
    
    optimizer = PerformanceOptimizer()
    
    # æ¨¡æ‹Ÿä¸€äº›å¼‚æ­¥ä»»åŠ¡
    async def mock_task(task_id: int):
        await asyncio.sleep(0.1)  # æ¨¡æ‹ŸI/Oæ“ä½œ
        return f"Task {task_id} completed"
    
    print("1. æ‰§è¡Œå¼‚æ­¥ä»»åŠ¡ä¼˜åŒ–...")
    tasks = [lambda i=i: mock_task(i) for i in range(20)]
    results = await optimizer.async_optimizer.batch_execute(tasks, batch_size=5)
    print(f"å®Œæˆ {len(results)} ä¸ªä»»åŠ¡")
    
    # ç¼“å­˜ä¼˜åŒ–æ¼”ç¤º
    print("\n2. ç¼“å­˜ä¼˜åŒ–æ¼”ç¤º...")
    cache = optimizer.cache_optimizer
    
    # è®¾ç½®ç¼“å­˜
    cache.set("user:1", {"name": "Alice", "email": "alice@example.com"})
    cache.set("user:2", {"name": "Bob", "email": "bob@example.com"})
    
    # è·å–ç¼“å­˜
    user1 = cache.get("user:1")
    user2 = cache.get("user:2")
    user3 = cache.get("user:3", "Not found")
    
    print(f"ç”¨æˆ·1: {user1}")
    print(f"ç”¨æˆ·3: {user3}")
    
    # æ€§èƒ½æŒ‡æ ‡æ”¶é›†
    print("\n3. æ€§èƒ½æŒ‡æ ‡æ”¶é›†...")
    metrics = optimizer.collect_metrics()
    print(f"å“åº”æ—¶é—´: {metrics.response_time:.3f}s")
    print(f"CPUä½¿ç”¨ç‡: {metrics.cpu_usage:.1f}%")
    print(f"å†…å­˜ä½¿ç”¨ç‡: {metrics.memory_usage:.1f}%")
    
    # ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š
    print("\n4. ä¼˜åŒ–æŠ¥å‘Šç”Ÿæˆ...")
    report = optimizer.generate_optimization_report()
    print("æ€§èƒ½æ‘˜è¦:")
    for key, value in report["performance_summary"].items():
        print(f"  {key}: {value}")
    
    print("\nä¼˜åŒ–å»ºè®®:")
    for recommendation in report["optimization_recommendations"]:
        print(f"  - {recommendation}")

if __name__ == "__main__":
    asyncio.run(demo_performance_optimization())
```

## ğŸ¯ å®è·µç»ƒä¹ 

### ç»ƒä¹ 1ï¼šå¼‚æ­¥æ€§èƒ½ä¼˜åŒ–
```python
class AsyncPerformanceOptimizer:
    """
    å¼‚æ­¥æ€§èƒ½ä¼˜åŒ–ç»ƒä¹ 
    
    è¦æ±‚ï¼š
    1. å®ç°åç¨‹æ± åŠ¨æ€è°ƒæ•´
    2. ä¼˜åŒ–å¼‚æ­¥I/Oæ“ä½œ
    3. å®ç°èƒŒå‹æ§åˆ¶æœºåˆ¶
    4. æ·»åŠ æ€§èƒ½ç›‘æ§å’Œå‘Šè­¦
    """
    
    async def optimize_async_operations(self, operations: List[Callable]) -> List[Any]:
        """ä¼˜åŒ–å¼‚æ­¥æ“ä½œ"""
        # TODO: å®ç°å¼‚æ­¥æ“ä½œä¼˜åŒ–
        pass
    
    async def implement_backpressure(self, producer, consumer):
        """å®ç°èƒŒå‹æ§åˆ¶"""
        # TODO: å®ç°èƒŒå‹æ§åˆ¶
        pass
```

### ç»ƒä¹ 2ï¼šå†…å­˜ä¼˜åŒ–ç­–ç•¥
```python
class MemoryOptimizer:
    """
    å†…å­˜ä¼˜åŒ–ç­–ç•¥ç»ƒä¹ 
    
    è¦æ±‚ï¼š
    1. å®ç°å†…å­˜æ± ç®¡ç†
    2. ä¼˜åŒ–å¯¹è±¡ç”Ÿå‘½å‘¨æœŸ
    3. å®ç°æ™ºèƒ½åƒåœ¾å›æ”¶
    4. æ·»åŠ å†…å­˜æ³„æ¼æ£€æµ‹
    """
    
    def optimize_memory_usage(self, objects: List[Any]) -> Dict[str, Any]:
        """ä¼˜åŒ–å†…å­˜ä½¿ç”¨"""
        # TODO: å®ç°å†…å­˜ä¼˜åŒ–
        pass
    
    def detect_memory_leaks(self) -> List[Dict[str, Any]]:
        """æ£€æµ‹å†…å­˜æ³„æ¼"""
        # TODO: å®ç°å†…å­˜æ³„æ¼æ£€æµ‹
        pass
```

## âœ… å­¦ä¹ æ£€æŸ¥

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œè¯·ç¡®è®¤æ‚¨èƒ½å¤Ÿï¼š

- [ ] ç†è§£æ€§èƒ½ä¼˜åŒ–çš„å±‚æ¬¡å’Œæ–¹æ³•è®º
- [ ] å®ç°å¼‚æ­¥ç¼–ç¨‹å’Œå¹¶å‘ä¼˜åŒ–
- [ ] è®¾è®¡é«˜æ•ˆçš„ç¼“å­˜å’Œè¿æ¥æ± ç­–ç•¥
- [ ] è¿›è¡Œæ€§èƒ½åˆ†æå’Œç“¶é¢ˆè¯†åˆ«
- [ ] å»ºç«‹æ€§èƒ½ç›‘æ§å’Œå‘Šè­¦æœºåˆ¶
- [ ] å®Œæˆå®è·µç»ƒä¹ 

## ğŸ“š ä¸‹ä¸€æ­¥

æ€§èƒ½ä¼˜åŒ–ç­–ç•¥æŒæ¡åï¼Œè¯·ç»§ç»­å­¦ä¹ ï¼š
- [å®¹å™¨åŒ–éƒ¨ç½²](./containerization-deployment.md)

---

**æ­å–œï¼æ‚¨å·²ç»æŒæ¡äº†æ€§èƒ½ä¼˜åŒ–çš„æ ¸å¿ƒæŠ€æœ¯ï¼** âš¡
